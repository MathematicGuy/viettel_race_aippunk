{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\apc\\appdata\\local\\temp\\pip-req-build-yuz3ma39\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from clip==1.0) (0.23.0+cu128)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torch->clip==1.0) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torchvision->clip==1.0) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from torchvision->clip==1.0) (11.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\apc\\miniconda3\\envs\\new\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\APC\\AppData\\Local\\Temp\\pip-req-build-yuz3ma39'\n"
     ]
    }
   ],
   "source": [
    "# %pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== IMPORTS =====\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pymilvus import MilvusClient, DataType, Function, FunctionType, AnnSearchRequest, RRFRanker\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac18b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a41da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== MODEL INITIALIZATION =====\n",
    "# Text embedding model\n",
    "text_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2').to(device)\n",
    "\n",
    "# Multimodal embedding model (CLIP cho text-image joint embedding)\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "\n",
    "# Image captioning model (InternVL3.5-2B-Instruct)\n",
    "# caption_tokenizer = AutoTokenizer.from_pretrained(\"OpenGVLab/InternVL3_5-2B-Instruct\", trust_remote_code=True)\n",
    "# caption_model = AutoModel.from_pretrained(\"OpenGVLab/InternVL3_5-2B-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9142c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_model device: cuda:0\n",
      "clip_model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"text_model device:\", next(text_model.parameters()).device)\n",
    "print(\"clip_model device:\", next(clip_model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ead0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MARKDOWN PROCESSOR =====\n",
    "class MarkdownProcessor:\n",
    "    \"\"\"Xử lý file markdown, trích xuất text, bảng, và hình ảnh\"\"\"\n",
    "\n",
    "    def __init__(self, markdown_dir: str, image_base_dir: str):\n",
    "        self.markdown_dir = Path(markdown_dir)\n",
    "        self.image_base_dir = Path(image_base_dir)\n",
    "\n",
    "    def extract_content(self, md_file: Path) -> Dict[str, Any]:\n",
    "        \"\"\"Trích xuất text, tables, và images từ markdown\"\"\"\n",
    "        with open(md_file, 'r', encoding='utf-8') as f:\n",
    "            md_content = f.read()\n",
    "\n",
    "        html = markdown.markdown(md_content, extensions=['tables', 'fenced_code'])\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        text_content = soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "        tables = []\n",
    "        for table in soup.find_all('table'):\n",
    "            table_text = table.get_text(separator=' | ', strip=True)\n",
    "            tables.append(table_text)\n",
    "\n",
    "        image_paths = []\n",
    "        img_pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
    "        for match in re.finditer(img_pattern, md_content):\n",
    "            img_path = match.group(1).strip()\n",
    "            if img_path.startswith(\"images/\"):\n",
    "                full_path = self.markdown_dir / img_path\n",
    "            else:\n",
    "                full_path = self.image_base_dir / img_path\n",
    "\n",
    "            if full_path.exists():\n",
    "                image_paths.append(str(full_path))\n",
    "\n",
    "        return {\n",
    "            'text': text_content,\n",
    "            'tables': tables,\n",
    "            'images': image_paths,\n",
    "            'source': str(md_file)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalImageEncoder:\n",
    "    \"\"\"Encode images and text with CLIP embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, clip_model, clip_preprocess):\n",
    "        self.clip_model = clip_model\n",
    "        self.clip_preprocess = clip_preprocess\n",
    "        self.device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Move model to device\n",
    "        self.clip_model = self.clip_model.to(self.device)\n",
    "\n",
    "    def encode_image_multimodal(self, image_path: str) -> List[float]:\n",
    "        \"\"\"Encode image into CLIP embedding vector\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_input = self.clip_preprocess(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                image_features = self.clip_model.encode_image(image_input)\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            return image_features.squeeze().cpu().numpy().tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding image {image_path}: {e}\")\n",
    "            # Return zero vector of appropriate dimension\n",
    "            return [0.0] * 512  # CLIP's standard dimension\n",
    "\n",
    "    def encode_text_for_image_search(self, text: str) -> List[float]:\n",
    "        \"\"\"Encode text into CLIP embedding vector for text-to-image search\"\"\"\n",
    "        try:\n",
    "            text_tokens = clip.tokenize(text).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                text_features = self.clip_model.encode_text(text_tokens)\n",
    "                text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            return text_features.squeeze().cpu().numpy().tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding text '{text}': {e}\")\n",
    "            # Return zero vector of appropriate dimension\n",
    "            return [0.0] * 512  # CLIP's standard dimension\n",
    "\n",
    "image_encoder = MultimodalImageEncoder(clip_model, clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ENTITY PROCESSORS =====\n",
    "class TextEntityProcessor:\n",
    "    \"\"\"Xử lý entity text riêng biệt\"\"\"\n",
    "\n",
    "    def __init__(self, text_model, chunk_size=500, overlap=100):\n",
    "        self.text_model = text_model\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap\n",
    "        )\n",
    "\n",
    "    def create_text_entities(self, content: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Tạo text entities\"\"\"\n",
    "        full_text = content['text']\n",
    "\n",
    "        # Thêm tables vào text nếu có\n",
    "        if content['tables']:\n",
    "            full_text += \"\\n\\n\" + \"\\n\\n\".join(content['tables'])\n",
    "\n",
    "        text_chunks = self.text_splitter.create_documents([full_text])\n",
    "\n",
    "        entities = []\n",
    "        for idx, chunk in enumerate(text_chunks):\n",
    "            # Text embedding\n",
    "            text_embedding = self.text_model.encode(chunk.page_content, convert_to_tensor=False).tolist()\n",
    "\n",
    "            entity = {\n",
    "                # 'id': f\"text_{idx}\",\n",
    "                'content': chunk.page_content,\n",
    "                'text_dense': text_embedding,  # Dense vector cho semantic search\n",
    "                'text_sparse': chunk.page_content,  # Text cho BM25 sparse search\n",
    "                'metadata': {\n",
    "                    'entity_type': 'text',\n",
    "                    'source': content['source'],\n",
    "                    'chunk_index': idx,\n",
    "                    'content_type': 'text_with_tables' if content['tables'] else 'text_only'\n",
    "                },\n",
    "                # Các trường image để trống\n",
    "                'image_path': '',\n",
    "                # 'image_caption': '',\n",
    "                'image_dense': [0.0] * 512  # Vector trống với đúng dimension\n",
    "            }\n",
    "            entities.append(entity)\n",
    "\n",
    "        return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8beeadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEntityProcessor:\n",
    "    \"\"\"Xử lý entity image riêng biệt\"\"\"\n",
    "\n",
    "    def __init__(self, image_encoder):\n",
    "        self.image_encoder = image_encoder\n",
    "\n",
    "    def create_image_entities(self, content: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Tạo image entities\"\"\"\n",
    "        entities = []\n",
    "\n",
    "        for idx, img_path in enumerate(content['images']):\n",
    "            # Generate caption\n",
    "            # caption = self.image_encoder.generate_caption(img_path)\n",
    "\n",
    "            # Multimodal embedding\n",
    "            image_embedding = self.image_encoder.encode_image_multimodal(img_path)\n",
    "\n",
    "            # Text embedding của caption (cho text search)\n",
    "            # caption_embedding = text_model.encode(caption, convert_to_tensor=False).tolist()\n",
    "\n",
    "            entity = {\n",
    "                # 'id': f\"image_{idx}\",\n",
    "                'content': \"\",  # Caption làm content chính\n",
    "                'image_path': img_path,\n",
    "                # 'image_caption': caption,\n",
    "                'image_dense': image_embedding,  # Multimodal vector cho image search\n",
    "                'metadata': {\n",
    "                    'entity_type': 'image',\n",
    "                    'source': content['source'],\n",
    "                    'image_index': idx,\n",
    "                    'original_path': img_path\n",
    "                },\n",
    "                # Các trường text bỏ trống cho image\n",
    "                'text_dense': [0.0] * 768,  # Dense vector của caption\n",
    "                # 'text_sparse': caption  # Caption text cho BM25\n",
    "            }\n",
    "            entities.append(entity)\n",
    "\n",
    "        return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = TextEntityProcessor(text_model)\n",
    "image_processor = ImageEntityProcessor(image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MILVUS HYBRID STORE =====\n",
    "class MilvusHybridStore:\n",
    "    \"\"\"Milvus store tối ưu cho hybrid search\"\"\"\n",
    "\n",
    "    def __init__(self, uri, token, collection_name=\"public\"):\n",
    "        self.client = MilvusClient(uri=uri, token=token)\n",
    "        self.collection_name = collection_name\n",
    "        self.text_dense_dim = 768  # paraphrase-multilingual-mpnet-base-v2\n",
    "        self.image_dense_dim = 512  # clip\n",
    "\n",
    "    def create_hybrid_collection(self):\n",
    "        \"\"\"Tạo collection cho hybrid search\"\"\"\n",
    "        # if self.client.has_collection(self.collection_name):\n",
    "        #     self.client.drop_collection(self.collection_name)\n",
    "\n",
    "        schema = self.client.create_schema(\n",
    "            auto_id=True,\n",
    "            enable_dynamic_fields=True\n",
    "        )\n",
    "\n",
    "        # Primary key\n",
    "        schema.add_field(\n",
    "            field_name=\"id\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            is_primary=True,\n",
    "            max_length=100\n",
    "        )\n",
    "\n",
    "        # Content field\n",
    "        schema.add_field(\n",
    "            field_name=\"content\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            max_length=8000,\n",
    "            enable_analyzer=True,\n",
    "        )\n",
    "\n",
    "        # Text fields\n",
    "        schema.add_field(\n",
    "            field_name=\"text_dense\",\n",
    "            datatype=DataType.FLOAT_VECTOR,\n",
    "            dim=self.text_dense_dim,\n",
    "        )\n",
    "\n",
    "        schema.add_field(\n",
    "            field_name=\"text_sparse\",\n",
    "            datatype=DataType.SPARSE_FLOAT_VECTOR,\n",
    "        )\n",
    "\n",
    "        # Image fields\n",
    "        schema.add_field(\n",
    "            field_name=\"image_dense\",\n",
    "            datatype=DataType.FLOAT_VECTOR,\n",
    "            dim=self.image_dense_dim,\n",
    "        )\n",
    "\n",
    "        schema.add_field(\n",
    "            field_name=\"image_path\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            max_length=500,\n",
    "        )\n",
    "\n",
    "        # schema.add_field(\n",
    "        #     field_name=\"image_caption\",\n",
    "        #     datatype=DataType.VARCHAR,\n",
    "        #     max_length=1000,\n",
    "        # )\n",
    "\n",
    "        # Metadata\n",
    "        schema.add_field(\n",
    "            field_name=\"metadata\",\n",
    "            datatype=DataType.JSON\n",
    "        )\n",
    "\n",
    "        # BM25 function cho text sparse\n",
    "        bm25_function = Function(\n",
    "            name=\"text_bm25_emb\",\n",
    "            function_type=FunctionType.BM25,\n",
    "            input_field_names=[\"content\"],\n",
    "            output_field_names=[\"text_sparse\"]\n",
    "        )\n",
    "        schema.add_function(bm25_function)\n",
    "\n",
    "        # Index parameters\n",
    "        index_params = self.client.prepare_index_params()\n",
    "\n",
    "        # Text dense index\n",
    "        index_params.add_index(\n",
    "            field_name=\"text_dense\",\n",
    "            index_type=\"HNSW\",\n",
    "            metric_type=\"COSINE\",\n",
    "            params={\"M\": 16, \"efConstruction\": 200}\n",
    "        )\n",
    "\n",
    "        # Text sparse index\n",
    "        index_params.add_index(\n",
    "            field_name=\"text_sparse\",\n",
    "            index_type=\"SPARSE_INVERTED_INDEX\",\n",
    "            metric_type=\"BM25\"\n",
    "        )\n",
    "\n",
    "        # Image dense index\n",
    "        index_params.add_index(\n",
    "            field_name=\"image_dense\",\n",
    "            index_type=\"HNSW\",\n",
    "            metric_type=\"COSINE\",\n",
    "            params={\"M\": 16, \"efConstruction\": 200}\n",
    "        )\n",
    "\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            schema=schema,\n",
    "            index_params=index_params\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Hybrid collection '{self.collection_name}' đã được tạo!\")\n",
    "\n",
    "    def insert_entities(self, entities: List[Dict[str, Any]]):\n",
    "        \"\"\"Insert entities vào collection\"\"\"\n",
    "        batch_size = 50\n",
    "        for i in range(0, len(entities), batch_size):\n",
    "            batch = entities[i:i + batch_size]\n",
    "\n",
    "            # Remove text_sparse from entities as it's generated by BM25 function\n",
    "            for entity in batch:\n",
    "                entity.pop('text_sparse', None)\n",
    "\n",
    "            self.client.insert(\n",
    "                collection_name=self.collection_name,\n",
    "                data=batch\n",
    "            )\n",
    "            print(f\"✅ Đã insert batch {i//batch_size + 1}/{(len(entities)-1)//batch_size + 1}\")\n",
    "\n",
    "        print(f\"✅ Đã insert {len(entities)} entities vào Milvus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import AnnSearchRequest, RRFRanker\n",
    "\n",
    "class HybridSearchEngine:\n",
    "    \"\"\"Engine cho hybrid search với multiple vectors từ text input\"\"\"\n",
    "\n",
    "    def __init__(self, milvus_store, text_model, image_encoder):\n",
    "        self.store = milvus_store\n",
    "        self.text_model = text_model\n",
    "        self.image_encoder = image_encoder\n",
    "\n",
    "    def hybrid_search(self, query_text: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Thực hiện hybrid search chỉ với text input\"\"\"\n",
    "\n",
    "        search_requests = []\n",
    "\n",
    "        if not query_text:\n",
    "            return []\n",
    "\n",
    "        # 1. Text semantic search với text embedding model\n",
    "        query_text_embedding = self.text_model.encode(query_text, convert_to_tensor=True, device=device).tolist()\n",
    "\n",
    "        text_search = AnnSearchRequest(\n",
    "            data=[query_text_embedding],\n",
    "            anns_field=\"text_dense\",\n",
    "            param={\"nprobe\": 10},\n",
    "            limit=limit\n",
    "        )\n",
    "        search_requests.append(text_search)\n",
    "\n",
    "        # 2. Full-text search (BM25) với sparse vectors\n",
    "        sparse_search = AnnSearchRequest(\n",
    "            data=[query_text],\n",
    "            anns_field=\"text_sparse\",\n",
    "            param={\"drop_ratio_search\": 0.2},\n",
    "            limit=limit\n",
    "        )\n",
    "        search_requests.append(sparse_search)\n",
    "\n",
    "        # 3. Multimodal search - embedding text bằng image encoder\n",
    "        query_image_embedding = self.image_encoder.encode_text_for_image_search(query_text)\n",
    "\n",
    "        image_search = AnnSearchRequest(\n",
    "            data=[query_image_embedding],\n",
    "            anns_field=\"image_dense\",\n",
    "            param={\"nprobe\": 10},\n",
    "            limit=limit\n",
    "        )\n",
    "        search_requests.append(image_search)\n",
    "\n",
    "        # Thực hiện hybrid search với RRF ranker\n",
    "        ranker = RRFRanker(100)\n",
    "\n",
    "        results = self.store.client.hybrid_search(\n",
    "            collection_name=self.store.collection_name,\n",
    "            reqs=search_requests,\n",
    "            ranker=ranker,\n",
    "            limit=limit,\n",
    "            output_fields=[\"content\", \"metadata\", \"image_path\"]\n",
    "        )\n",
    "\n",
    "        return results[0] if results else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01baab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAIN PIPELINE =====\n",
    "def create_hybrid_pipeline(markdown_dir: str, image_base_dir: str,\n",
    "                            uri: str, token: str):\n",
    "    \"\"\"Tạo pipeline hybrid search hoàn chỉnh\"\"\"\n",
    "\n",
    "    # Initialize components\n",
    "    processor = MarkdownProcessor(markdown_dir, image_base_dir)\n",
    "    store = MilvusHybridStore(uri, token)\n",
    "    search_engine = HybridSearchEngine(store, text_model, image_encoder)\n",
    "\n",
    "    # Tạo collection\n",
    "    store.create_hybrid_collection()\n",
    "\n",
    "    def process_documents(markdown_files: List[str]):\n",
    "        \"\"\"Xử lý documents thành entities\"\"\"\n",
    "        all_entities = []\n",
    "\n",
    "        for md_file in markdown_files:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Đang xử lý: {md_file}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "            # Extract content\n",
    "            content = processor.extract_content(Path(md_file))\n",
    "            print(f\"  - Text length: {len(content['text'])} ký tự\")\n",
    "            print(f\"  - Số bảng: {len(content['tables'])}\")\n",
    "            print(f\"  - Số hình ảnh: {len(content['images'])}\")\n",
    "\n",
    "            # Tạo text entities\n",
    "            text_entities = text_processor.create_text_entities(content)\n",
    "            print(f\"  - Text entities: {len(text_entities)}\")\n",
    "\n",
    "            # Tạo image entities\n",
    "            image_entities = image_processor.create_image_entities(content)\n",
    "            print(f\"  - Image entities: {len(image_entities)}\")\n",
    "\n",
    "            all_entities.extend(text_entities)\n",
    "            all_entities.extend(image_entities)\n",
    "\n",
    "                # Insert vào Milvus\n",
    "        store.insert_entities(all_entities)\n",
    "\n",
    "        print(f\"\\n✅ Pipeline hoàn tất! Tổng cộng {len(all_entities)} entities đã được xử lý.\")\n",
    "        return all_entities, search_engine\n",
    "\n",
    "    return process_documents, search_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572bf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Public001',\n",
       " 'Public002',\n",
       " 'Public003',\n",
       " 'Public004',\n",
       " 'Public005',\n",
       " 'Public006',\n",
       " 'Public007',\n",
       " 'Public008',\n",
       " 'Public009',\n",
       " 'Public010',\n",
       " 'Public011',\n",
       " 'Public012',\n",
       " 'Public013',\n",
       " 'Public014',\n",
       " 'Public015',\n",
       " 'Public016',\n",
       " 'Public017',\n",
       " 'Public018',\n",
       " 'Public019',\n",
       " 'Public020',\n",
       " 'Public021',\n",
       " 'Public022',\n",
       " 'Public023',\n",
       " 'Public024',\n",
       " 'Public025',\n",
       " 'Public026',\n",
       " 'Public027',\n",
       " 'Public028',\n",
       " 'Public029',\n",
       " 'Public030',\n",
       " 'Public031',\n",
       " 'Public032',\n",
       " 'Public033',\n",
       " 'Public034',\n",
       " 'Public035',\n",
       " 'Public036',\n",
       " 'Public037',\n",
       " 'Public038',\n",
       " 'Public039',\n",
       " 'Public040',\n",
       " 'Public041',\n",
       " 'Public042',\n",
       " 'Public043',\n",
       " 'Public044',\n",
       " 'Public045',\n",
       " 'Public046',\n",
       " 'Public047',\n",
       " 'Public048',\n",
       " 'Public049',\n",
       " 'Public050',\n",
       " 'Public051',\n",
       " 'Public052',\n",
       " 'Public053',\n",
       " 'Public054',\n",
       " 'Public055',\n",
       " 'Public056',\n",
       " 'Public057',\n",
       " 'Public058',\n",
       " 'Public059',\n",
       " 'Public060']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"data/training_input/\"\n",
    "file_names = [f for f in os.listdir(PATH) if f.lower().endswith(\".pdf\")]\n",
    "file_names = [f[:-4] for f in file_names]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# IMAGE_BASE_DIR = 'test_data/images'\n",
    "# MILVUS_URI = \"http://localhost:19530\"\n",
    "# MILVUS_TOKEN = \"root:Milvus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMAGE_BASE_DIR = 'test_data/images'\n",
    "MILVUS_URI = \"https://in03-7b3b56e59d62e9d.serverless.aws-eu-central-1.cloud.zilliz.com\"\n",
    "MILVUS_TOKEN = \"30cff684b802d87f26e0c7ea80e43c759237808981ac1563ae400b00316ff84be4261492ee91b9f55ec6ad8a25b7be9b483fc957\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e013a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_name in file_names:\n",
    "#     MARKDOWN_DIR = f'out\\\\{file_name}'\n",
    "#     process_docs, search_engine = create_hybrid_pipeline(\n",
    "#         MARKDOWN_DIR, IMAGE_BASE_DIR, MILVUS_URI, MILVUS_TOKEN\n",
    "#     )\n",
    "\n",
    "#     # Xử lý documents\n",
    "#     markdown_files = list(Path(MARKDOWN_DIR).glob(\"*.md\"))\n",
    "#     print(markdown_files)\n",
    "#     entities, search_engine = process_docs(markdown_files) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883556ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "store = MilvusHybridStore(MILVUS_URI, MILVUS_TOKEN)\n",
    "search_engine = HybridSearchEngine(store, text_model, image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e079569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST HYBRID SEARCH\n",
      "============================================================\n",
      "Text search results: 5\n",
      "'  1. Score: 0.0195'\n",
      "('     Content: Công nghệ ứng dụng vào mô hình nhà thông minh dựa trên '\n",
      " 'Internet vạn vật (IoT - Internet of Things) phần lớn bị hạn chế và phân tán. '\n",
      " 'Các đánh giá trong bài viết được thực hiện để phân loại bối cảnh nghiên cứu '\n",
      " 'về ứng dụng IoT xây dựng mô hình nhà thông minh, nhằm cung cấp những hiểu '\n",
      " 'biết có giá trị về công nghệ và hỗ trợ các nhà nghiên cứu hiểu các nền tảng '\n",
      " 'có sẵn và các lỗ hổng trong lĩnh vực này. Chúng tôi tiến hành tìm kiếm các '\n",
      " 'bài viết liên quan đến (1) nhà thông minh, (2) ứng dụng và (3) IoT...')\n",
      "'     Type: text'\n",
      "'  2. Score: 0.0192'\n",
      "('     Content: 1.5 Nhà thông minh từ sau năm 2010\\n'\n",
      " 'Trong phần này sẽ tập trung vào sự tích hợp của nhà thông minh, IoT và điện '\n",
      " 'toán đám mây để xác định một mô hình điện toán mới. Có thể tìm thấy trong '\n",
      " 'phần tài liệu các cuộc khảo sát và nghiên cứu về nhà thông minh, IoT và điện '\n",
      " 'toán đám mây, các thuộc tính, tính năng, công nghệ và nhược điểm của chúng. '\n",
      " '(KR Sollins, 2019)....')\n",
      "'     Type: text'\n",
      "'  3. Score: 0.0099'\n",
      "('     Content: Dịch máy là một trong những hướng nghiên cứu quan trọng trong '\n",
      " 'xử lý ngôn ngữ tự nhiên. Trong những năm gần đây, dịch máy nơ ron đã và đang '\n",
      " 'được nghiên cứu phổ biến hơn trong cộng đồng dịch máy vì hiện tại nó cho '\n",
      " 'chất lượng dịch tốt hơn so với phương pháp dịch máy thống kê truyền thống. '\n",
      " 'Tuy nhiên, dịch máy nơ ron lại cần lượng lớn dữ liệu song ngữ để huấn luyện. '\n",
      " 'Hệ dịch sẽ cho chất lượng bản dịch tốt hơn khi nó được thử nghiệm trong cùng '\n",
      " 'miền với miền dữ liệu mà nó được huấn luyện, ngược lại thì...')\n",
      "'     Type: text'\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TEST HYBRID SEARCH\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Text search\n",
    "text_results = search_engine.hybrid_search(\n",
    "    query_text=\"Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\",\n",
    "    limit=5\n",
    ")\n",
    "print(f\"Text search results: {len(text_results)}\")\n",
    "for i, result in enumerate(text_results[:3]):\n",
    "    pprint(f\"  {i+1}. Score: {result['distance']:.4f}\")\n",
    "    pprint(f\"     Content: {result['entity']['content']}...\")\n",
    "    pprint(f\"     Type: {result['entity']['metadata']['entity_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f2e8c",
   "metadata": {},
   "source": [
    "## LLM with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28fbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.548063744"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.memory_allocated() / 1e9  # check memory in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7e699c",
   "metadata": {},
   "source": [
    "## Full Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain_core.output_parsers import PydanticOutputParser\n",
    "# import re\n",
    "\n",
    "# # --- Define Output Model ---\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# class MCQAnswer(BaseModel):\n",
    "#     answer: str\n",
    "#     explanation: str\n",
    "\n",
    "# class MCQInput(BaseModel):\n",
    "#     question: str\n",
    "#     option_a: str\n",
    "#     option_b: str\n",
    "#     option_c: str\n",
    "#     option_d: str\n",
    "\n",
    "# # --- Define Prompt ---\n",
    "# parser = PydanticOutputParser(pydantic_object=MCQAnswer)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=(\n",
    "#         \"You are a strict assistant. \"\n",
    "#         \"Use the given context to answer the multiple-choice question below.\\n\\n\"\n",
    "#         \"Return only a JSON object in this format:\\n\"\n",
    "#         \"{{\\\"answer\\\": \\\"<A|B|C|D>\\\", \\\"explanation\\\": \\\"<short reason>\\\"}}\\n\\n\"\n",
    "#         \"Context: {context}\\n\"\n",
    "#         \"Question: {question}\\n\"\n",
    "#         \"A. {option_a}\\nB. {option_b}\\nC. {option_c}\\nD. {option_d}\\n\\n\"\n",
    "#         \"Return *only* a JSON object matching this schema:\\n\"\n",
    "#         \"{format_instructions}\\n\"\n",
    "#         \"Do not add any extra text.\\n\"\n",
    "#     ),\n",
    "#     input_variables=[\"context\", \"question\", \"option_a\", \"option_b\", \"option_c\", \"option_d\"],\n",
    "#     partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "# )\n",
    "\n",
    "# # --- Create Chain ---\n",
    "# full_chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95195372",
   "metadata": {},
   "source": [
    "### Demo Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: You are a strict assistant. Use the given context to answer the multiple-choice question below.\n",
      "\n",
      "Return only a JSON object in this format:\n",
      "{\"answer\": \"<A|B|C|D>\", \"explanation\": \"<short reason>\"}\n",
      "\n",
      "Context: [Document(metadata={'entity_type': 'text', 'source': 'out\\\\Public001\\\\main.md', 'chunk_index': 0, 'content_type': 'text_only'}, page_content='Công nghệ ứng dụng vào mô hình nhà thông minh dựa trên Internet vạn vật (IoT - Internet of Things) phần lớn bị hạn chế và phân tán. Các đánh giá trong bài viết được thực hiện để phân loại bối cảnh nghiên cứu về ứng dụng IoT xây dựng mô hình nhà thông minh, nhằm cung cấp những hiểu biết có giá trị về công nghệ và hỗ trợ các nhà nghiên cứu hiểu các nền tảng có sẵn và các lỗ hổng trong lĩnh vực này. Chúng tôi tiến hành tìm kiếm các bài viết liên quan đến (1) nhà thông minh, (2) ứng dụng và (3) IoT'), Document(metadata={'entity_type': 'text', 'source': 'out\\\\Public001\\\\main.md', 'chunk_index': 4, 'content_type': 'text_only'}, page_content='Nhà thông minh cổ điển, IOT, điện toán đám mây (Cloud Computing) và xử lý sự kiện dựa trên quy tắc, là những nền tảng của nhà thông minh tiên tiến. Mỗi nền tảng đóng góp các thuộc tính và công nghệ cốt lõi của nó. IoT thì kết nối internet và quản lý từ xa các thiết bị di động, được tích hợp với nhiều loại cảm biến. Cảm biến có thể được gắn vào các thiết bị gia đình chẳng hạn như máy lạnh, đèn và các thiết bị khác. Điện toán đám mây cung cấp khả năng tính toán, không gian lưu trữ, phát triển các'), Document(metadata={'entity_type': 'text', 'source': 'out\\\\Public001\\\\main.md', 'chunk_index': 2, 'content_type': 'text_only'}, page_content='IoT trong mô hình xây dựng nhà thông minh, lớp thứ hai bao gồm các tài liệu ứng dụng IoT và việc sử dụng chúng, lớp thứ ba chứa các đề xuất để phát triển và vận hành các ứng dụng IoT, lớp cuối cùng bao gồm các nghiên cứu thực tế để phát triển IoT ứng dụng nhà thông minh. Sau đó xác định các đặc điểm cơ bản của lĩnh vực mới này theo các khía cạnh: sử dụng IoT vào nhà thông minh cùng những thách thức và các đề xuất để cải tiến.'), Document(metadata={'entity_type': 'text', 'source': 'out\\\\Public001\\\\main.md', 'chunk_index': 1, 'content_type': 'text_only'}, page_content='Chúng tôi tiến hành tìm kiếm các bài viết liên quan đến (1) nhà thông minh, (2) ứng dụng và (3) IoT trong ba cơ sở dữ liệu chính, cụ thể là: Web of Science, ScienceDirect và IEEE Explore. Các cơ sở dữ liệu này chứa tài liệu về các ứng dụng nhà thông minh sử dụng IoT. Tập dữ liệu thu được bao gồm 229 bài báo được chia thành bốn lớp. Lớp đầu tiên bao gồm các bài viết đánh giá và khảo sát liên quan đến IoT trong mô hình xây dựng nhà thông minh, lớp thứ hai bao gồm các tài liệu ứng dụng IoT và việc'), Document(metadata={'entity_type': 'text', 'source': 'out\\\\Public001\\\\main.md', 'chunk_index': 54, 'content_type': 'text_only'}, page_content='1.5 Nhà thông minh từ sau năm 2010\\nTrong phần này sẽ tập trung vào sự tích hợp của nhà thông minh, IoT và điện toán đám mây để xác định một mô hình điện toán mới. Có thể tìm thấy trong phần tài liệu các cuộc khảo sát và nghiên cứu về nhà thông minh, IoT và điện toán đám mây, các thuộc tính, tính năng, công nghệ và nhược điểm của chúng. (KR Sollins, 2019).')]\n",
      "Question: Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\n",
      "A. Lưu trữ dữ liệu trên máy chủ\n",
      "B. Kết nối Internet và quản lý thiết bị từ xa\n",
      "C. Cung cấp dịch vụ phân tích dữ liệu lớn\n",
      "D. Thay thế hoàn toàn điện toán đám mây\n",
      "\n",
      "Return *only* a JSON object matching this schema:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"answer\": {\"title\": \"Answer\", \"type\": \"string\"}, \"explanation\": {\"title\": \"Explanation\", \"type\": \"string\"}}, \"required\": [\"answer\", \"explanation\"]}\n",
      "```\n",
      "Do not add any extra text.\n",
      "{\"answer\": \"B\", \"explanation\": \"IoT trong mô hình nhà thông minh chủ yếu giúp kết nối Internet và quản lý thiết bị di động từ xa.\"}\n"
     ]
    }
   ],
   "source": [
    "# # --- Input ---\n",
    "# mcq = MCQInput(\n",
    "#     question=\"Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\",\n",
    "#     option_a=\"Lưu trữ dữ liệu trên máy chủ\",\n",
    "#     option_b=\"Kết nối Internet và quản lý thiết bị từ xa\",\n",
    "#     option_c=\"Cung cấp dịch vụ phân tích dữ liệu lớn\",\n",
    "#     option_d=\"Thay thế hoàn toàn điện toán đám mây\",\n",
    "# )\n",
    "\n",
    "# retrieved_context = get_relevant_documents(\"Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì ?\")\n",
    "# response = llm.invoke(prompt.format(**mcq.model_dump(), context=retrieved_context))\n",
    "# print(\"Raw response:\", response)  # Check if it's a dict with 'text' key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: B\n",
      "Explanation: IoT trong mô hình nhà thông minh chủ yếu giúp kết nối Internet và quản lý từ xa các thiết bị di động, được tích hợp với nhiều loại cảm biến.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #? Extract answer and explanation using regex\n",
    "# pattern = r'\\{\"answer\":\\s*\"([A-D])\",\\s*\"explanation\":\\s*\"([^\"]+)\"\\}'\n",
    "# match = re.search(pattern, response)\n",
    "\n",
    "# if match:\n",
    "#     answer = match.group(1)\n",
    "#     explanation = match.group(2)\n",
    "\n",
    "#     print(f\"Answer: {answer}\")\n",
    "#     print(f\"Explanation: {explanation}\")\n",
    "# else:\n",
    "#     print(\"No match found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516dc610",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6abff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoModelForImageTextToText, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "\n",
    "def load_llm():\n",
    "    MODEL_PATH = \"Qwen/Qwen2.5-3B-Instruct\"  # Local model path\n",
    "\n",
    "    # ✅ Optimized 4-bit quantization config for Blackwell GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,     # Nested quantization → less VRAM\n",
    "        bnb_4bit_quant_type=\"nf4\",          # Best quantization format for LLMs\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,  # BF16 is optimal on Blackwell\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer & model locally with full GPU optimization\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",                  # Automatically spreads across GPUs if available\n",
    "        dtype=torch.bfloat16,         # Native dtype for new NVIDIA architectures\n",
    "        local_files_only=True,\n",
    "    )\n",
    "\n",
    "    # ✅ Enable better CUDA performance\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True     # TensorFloat-32 acceleration\n",
    "    torch.backends.cudnn.benchmark = True            # Optimize kernel selection\n",
    "    torch.set_float32_matmul_precision(\"high\")       # Prefer high precision kernels\n",
    "\n",
    "    # ✅ Create high-throughput inference pipeline\n",
    "    generation_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=generation_pipeline)\n",
    "\n",
    "llm = load_llm()\n",
    "print(\"Model device:\", next(llm.pipeline.model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ecd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "\"\"\"\n",
    "{\n",
    "    \"id\": null,\n",
    "    \"metadata\": {\n",
    "        \"entity_type\": \"text\",\n",
    "        \"source\": \"out\\\\Public001\\\\main.md\",\n",
    "        \"chunk_index\": 0,\n",
    "        \"content_type\": \"text_only\"\n",
    "    },\n",
    "    \"page_content\": \"Công nghệ ứng dụng vào mô hình nhà thông minh dựa trên Internet vạn vật (IoT - Internet of Things) phần lớn bị hạn chế và phân tán. Các đánh giá trong bài viết được thực hiện để phân loại bối cảnh nghiên cứu về ứng dụng IoT xây dựng mô hình nhà thông minh, nhằm cung cấp những hiểu biết có giá trị về công nghệ và hỗ trợ các nhà nghiên cứu hiểu các nền tảng có sẵn và các lỗ hổng trong lĩnh vực này. Chúng tôi tiến hành tìm kiếm các bài viết liên quan đến (1) nhà thông minh, (2) ứng dụng và (3) IoT\",\n",
    "    \"type\": \"Document\"\n",
    "},\n",
    "\"\"\"\n",
    "\n",
    "# def get_relevant_documents(query: str) -> list[Document]:\n",
    "#     results = search_engine.hybrid_search(query, limit=5)\n",
    "#     docs = []\n",
    "#     for result in results:\n",
    "#         content = result['entity']['content']\n",
    "#         if result['entity']['image_path']:\n",
    "#             content += f\" [Image: {result['entity']['image_path']}]\"\n",
    "\n",
    "#         docs.append(Document(page_content=content, metadata=result['entity']['metadata']))\n",
    "\n",
    "#     return docs\n",
    "\n",
    "def get_relevant_documents(query: str) -> list[Document]:\n",
    "    results = search_engine.hybrid_search(query, limit=5)\n",
    "    docs = []\n",
    "    for result in results:\n",
    "        content = result['entity']['content']\n",
    "        if result['entity']['image_path']:\n",
    "            # Đọc và mã hóa hình ảnh thành base64 để nhúng vào context\n",
    "            try:\n",
    "                image_path = result['entity']['image_path']\n",
    "                with Image.open(image_path) as img:\n",
    "                    buffered = BytesIO()\n",
    "                    img.save(buffered, format=\"PNG\")\n",
    "                    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "                    content += f\" <image>{img_str}</image>\"  # Định dạng phù hợp với Qwen-VL\n",
    "            except Exception as e:\n",
    "                content += f\" [Failed to load image: {str(e)}]\"\n",
    "\n",
    "        docs.append(Document(page_content=content, metadata=result['entity']['metadata']))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68671af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import re\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "csv_path = \"question.csv\"  # Update if needed\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "class MCQAnswer(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "class MCQInput(BaseModel):\n",
    "    question: str\n",
    "    option_a: str\n",
    "    option_b: str\n",
    "    option_c: str\n",
    "    option_d: str\n",
    "\n",
    "\n",
    "# --- Define Prompt ---\n",
    "parser = PydanticOutputParser(pydantic_object=MCQAnswer)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"You are a strict assistant. \"\n",
    "        \"Use the given context to answer the multiple-choice question below.\\n\\n\"\n",
    "        \"Return only a JSON object in this format:\\n\"\n",
    "        \"{{\\\"answer\\\": \\\"<A|B|C|D>\\\"}}\\n\\n\"\n",
    "        \"Context: {context}\\n\"\n",
    "        \"Question: {question}\\n\"\n",
    "        \"A. {option_a}\\nB. {option_b}\\nC. {option_c}\\nD. {option_d}\\n\\n\"\n",
    "        \"Return the correct answer as letter (i.e. A, B, C, D). If there are multiple correct answer then seperate them by a comma e.g. 'A, B'\"\n",
    "        \"Do not add any extra text.\\n\"\n",
    "    ),\n",
    "    input_variables=[\"context\", \"question\", \"option_a\", \"option_b\", \"option_c\", \"option_d\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# --- Create Chain ---\n",
    "full_chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: You are a strict assistant. Use the given context to answer the multiple-choice question below.\n",
      "\n",
      "Return only a JSON object in this format:\n",
      "{\"answer\": \"<A|B|C|D>\"}\n",
      "\n",
      "Context: IoT trong nhà thông minh giúp kết nối, điều khiển và quản lý các thiết bị qua mạng Internet.\n",
      "Question: Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\n",
      "A. Lưu trữ dữ liệu trên máy chủ\n",
      "B. Kết nối Internet và quản lý thiết bị từ xa\n",
      "C. Cung cấp dịch vụ phân tích dữ liệu lớn\n",
      "D. Thay thế hoàn toàn điện toán đám mây\n",
      "\n",
      "Return the correct answer as letter (i.e. A, B, C, D). If there are multiple correct answer then seperate them by a comma e.g. 'A, B'Do not add any extra text.\n",
      "{\"answer\": \"B\"}\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Input ---\n",
    "mcq = MCQInput(\n",
    "    question=\"Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\",\n",
    "    option_a=\"Lưu trữ dữ liệu trên máy chủ\",\n",
    "    option_b=\"Kết nối Internet và quản lý thiết bị từ xa\",\n",
    "    option_c=\"Cung cấp dịch vụ phân tích dữ liệu lớn\",\n",
    "    option_d=\"Thay thế hoàn toàn điện toán đám mây\",\n",
    ")\n",
    "\n",
    "context = \"IoT trong nhà thông minh giúp kết nối, điều khiển và quản lý các thiết bị qua mạng Internet.\"\n",
    "response = llm.invoke(prompt.format(**mcq.model_dump(), context=context))\n",
    "print(\"Raw response:\", response)\n",
    "\n",
    "# Extract answer using regex\n",
    "pattern = r'\\{\"answer\":\\s*\"([A-D, ]+)\"\\}'\n",
    "match = re.search(pattern, response)\n",
    "\n",
    "if match:\n",
    "    answer = match.group(1)\n",
    "    print(f\"{answer}\")\n",
    "else:\n",
    "    print(\"No match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0d93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions loaded: 300\n",
      "Processing question 1: Trong mô hình nhà thông minh, IoT chủ yếu đóng vai trò gì?\n",
      "B\n",
      "Processing question 2: Năm 2010, công nghệ nào thường được sử dụng trong kiểm soát ra vào ngôi nhà thông minh?\n",
      "B\n",
      "Processing question 3: Bộ cảm biến trong nhà thông minh thực hiện chức năng gì và bộ truyền động có vai trò gì?\n",
      "C\n",
      "Processing question 4: Nội dung chính của bài báo nghiên cứu về IoT trong xây dựng nhà thông minh là gì?\n",
      "C\n",
      "Processing question 5: Trong nghiên cứu, 229 bài báo được chia thành 4 lớp. Trung bình mỗi lớp có bao nhiêu bài?\n",
      "B\n",
      "Processing question 6: Học phần Bảo mật Web trang bị kiến thức về bộ rủi ro phổ biến nào?\n",
      "A\n",
      "Processing question 7: Trong học phần Cơ sở dữ liệu nâng cao, loại CSDL nào sau đây không được đề cập?\n",
      "D\n",
      "Processing question 8: Học phần bảo mật web, csdl dạy nội dung gì?\n",
      "A\n",
      "Processing question 9: Nhóm môn học trong tài liệu Public002 tập trung cung cấp cho sinh viên kiến thức tổng quan về lĩnh vực nào?\n",
      "Error encoding text 'Nhóm môn học trong tài liệu Public002 tập trung cung cấp cho sinh viên kiến thức tổng quan về lĩnh vực nào?': Input Nhóm môn học trong tài liệu Public002 tập trung cung cấp cho sinh viên kiến thức tổng quan về lĩnh vực nào? is too long for context length 77\n",
      "B\n",
      "Processing question 10: Có 35 học phần được liệt kê trong đoạn tài liệu (từ số 47 đến 81). Trung bình mỗi trang mô tả bao nhiêu học phần (giả sử trải đều trên 7 trang)?\n",
      "Error encoding text 'Có 35 học phần được liệt kê trong đoạn tài liệu (từ số 47 đến 81). Trung bình mỗi trang mô tả bao nhiêu học phần (giả sử trải đều trên 7 trang)?': Input Có 35 học phần được liệt kê trong đoạn tài liệu (từ số 47 đến 81). Trung bình mỗi trang mô tả bao nhiêu học phần (giả sử trải đều trên 7 trang)? is too long for context length 77\n",
      "D\n",
      "Processing question 11: Điểm BLEU được dùng để đánh giá chất lượng bản dịch trong nghiên cứu này là gì?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "Processing question 12: Công cụ nào được nhóm tác giả sử dụng để huấn luyện các hệ dịch nơ ron?\n",
      "B\n",
      "Processing question 13: Điểm BLEU và công cụ huấn luyện hệ dịch nơ ron trong nghiên cứu này là gì?\n",
      "D\n",
      "Processing question 14: Nội dung chính của bài báo Public003 là gì?\n",
      "B\n",
      "Processing question 15: Theo kết quả thử nghiệm, hệ dịch Adapt_System cải thiện bao nhiêu điểm BLEU so với Baseline_G trong miền pháp lý?\n",
      "Error encoding text 'Theo kết quả thử nghiệm, hệ dịch Adapt_System cải thiện bao nhiêu điểm BLEU so với Baseline_G trong miền pháp lý?': Input Theo kết quả thử nghiệm, hệ dịch Adapt_System cải thiện bao nhiêu điểm BLEU so với Baseline_G trong miền pháp lý? is too long for context length 77\n",
      "D\n",
      "Processing question 16: Công nghệ in bê tông 3D được thực hiện theo quy trình nào?\n",
      "C\n",
      "Processing question 17: Công nghệ nào được phát triển tại Đại học Loughborough (Anh)?\n",
      "B\n",
      "Processing question 18: Công nghệ in bê tông 3D nào vừa cho phép kiểm soát tốt cấu trúc sản phẩm, vừa sử dụng bê tông cốt liệu sợi tổng hợp cường độ cao?\n",
      "Error encoding text 'Công nghệ in bê tông 3D nào vừa cho phép kiểm soát tốt cấu trúc sản phẩm, vừa sử dụng bê tông cốt liệu sợi tổng hợp cường độ cao?': Input Công nghệ in bê tông 3D nào vừa cho phép kiểm soát tốt cấu trúc sản phẩm, vừa sử dụng bê tông cốt liệu sợi tổng hợp cường độ cao? is too long for context length 77\n",
      "B\n",
      "Processing question 19: Nội dung chính của bài báo Public004 là gì?\n",
      "C\n",
      "Processing question 20: Trong tài liệu, ưu điểm của công nghệ Contour Crafting so với Concrete Printing là gì?\n",
      "A\n",
      "Processing question 21: OCR là viết tắt của gì trong bài báo này?\n",
      "A\n",
      "Processing question 22: Giải pháp thử nghiệm tại Học viện Ngân hàng được lựa chọn là gì?\n",
      "B\n",
      "Processing question 23: Công nghệ nào vừa cho phép máy tính tự động nhận biết ký tự trên hình ảnh, vừa có khả năng đọc hiểu dữ liệu chữ viết tay và chữ in?\n",
      "Error encoding text 'Công nghệ nào vừa cho phép máy tính tự động nhận biết ký tự trên hình ảnh, vừa có khả năng đọc hiểu dữ liệu chữ viết tay và chữ in?': Input Công nghệ nào vừa cho phép máy tính tự động nhận biết ký tự trên hình ảnh, vừa có khả năng đọc hiểu dữ liệu chữ viết tay và chữ in? is too long for context length 77\n",
      "B\n",
      "Processing question 24: Nội dung chính của bài báo Public005 là gì?\n",
      "D\n",
      "Processing question 25: Trong thử nghiệm, tỷ lệ sai số theo đơn vị từ của FPT.AI Reader là bao nhiêu?\n",
      "C\n",
      "Processing question 26: Luật nào quy định rõ nhiệm vụ, quyền hạn của các thiết chế quản trị đại học ở Việt Nam?\n",
      "Error encoding text 'Luật nào quy định rõ nhiệm vụ, quyền hạn của các thiết chế quản trị đại học ở Việt Nam?': Input Luật nào quy định rõ nhiệm vụ, quyền hạn của các thiết chế quản trị đại học ở Việt Nam? is too long for context length 77\n",
      "B\n",
      "Processing question 27: Theo bài báo, cơ quan nào có thẩm quyền cao nhất trong trường đại học?\n",
      "A\n",
      "Processing question 28: Ứng dụng công nghệ số trong quản trị đại học giúp vừa bao quát toàn bộ hoạt động của nhà trường kịp thời, vừa hỗ trợ ra quyết sách quản lý và điều hành hiệu quả.\n",
      "Error encoding text 'Ứng dụng công nghệ số trong quản trị đại học giúp vừa bao quát toàn bộ hoạt động của nhà trường kịp thời, vừa hỗ trợ ra quyết sách quản lý và điều hành hiệu quả.': Input Ứng dụng công nghệ số trong quản trị đại học giúp vừa bao quát toàn bộ hoạt động của nhà trường kịp thời, vừa hỗ trợ ra quyết sách quản lý và điều hành hiệu quả. is too long for context length 77\n",
      "B\n",
      "Processing question 29: Nội dung chính của bài báo Public006 là gì?\n",
      "D\n",
      "Processing question 30: Theo số liệu trong tài liệu, đến nay ngành giáo dục đã số hóa dữ liệu của khoảng bao nhiêu giáo viên và học sinh?\n",
      "Error encoding text 'Theo số liệu trong tài liệu, đến nay ngành giáo dục đã số hóa dữ liệu của khoảng bao nhiêu giáo viên và học sinh?': Input Theo số liệu trong tài liệu, đến nay ngành giáo dục đã số hóa dữ liệu của khoảng bao nhiêu giáo viên và học sinh? is too long for context length 77\n",
      "D\n",
      "Processing question 31: ISO 15189:2022 áp dụng cho đối tượng nào?\n",
      "B\n",
      "Processing question 32: Theo tiêu chuẩn, “khiếu nại” được định nghĩa như thế nào?\n",
      "C\n",
      "Processing question 33: Trong các tiêu chuẩn ISO/IEC liên quan đến đo lường và đánh giá sự phù hợp, tiêu chuẩn nào vừa cung cấp từ vựng quốc tế về đo lường, vừa được sử dụng để xác định các thuật ngữ về độ chệch và khoảng tham chiếu sinh học?\n",
      "Error encoding text 'Trong các tiêu chuẩn ISO/IEC liên quan đến đo lường và đánh giá sự phù hợp, tiêu chuẩn nào vừa cung cấp từ vựng quốc tế về đo lường, vừa được sử dụng để xác định các thuật ngữ về độ chệch và khoảng tham chiếu sinh học?': Input Trong các tiêu chuẩn ISO/IEC liên quan đến đo lường và đánh giá sự phù hợp, tiêu chuẩn nào vừa cung cấp từ vựng quốc tế về đo lường, vừa được sử dụng để xác định các thuật ngữ về độ chệch và khoảng tham chiếu sinh học? is too long for context length 77\n",
      "B\n",
      "Processing question 34: Nội dung chính của tiêu chuẩn ISO 15189:2022 là gì?\n",
      "B\n",
      "Processing question 35: Theo tiêu chuẩn, “khoảng tham chiếu sinh học” thường được định nghĩa ở mức bao nhiêu phần trăm giá trị tập trung?\n",
      "Error encoding text 'Theo tiêu chuẩn, “khoảng tham chiếu sinh học” thường được định nghĩa ở mức bao nhiêu phần trăm giá trị tập trung?': Input Theo tiêu chuẩn, “khoảng tham chiếu sinh học” thường được định nghĩa ở mức bao nhiêu phần trăm giá trị tập trung? is too long for context length 77\n",
      "A\n",
      "Processing question 36: Giám đốc phòng xét nghiệm theo ISO 15189:2022 có thể ủy quyền nhiệm vụ cho ai?\n",
      "B\n",
      "Processing question 37: ISO 15189:2022 yêu cầu thiết lập và theo dõi chỉ số chất lượng nào dưới đây?\n",
      "C\n",
      "Processing question 38: Khi lựa chọn, vận hành và bảo dưỡng thiết bị phòng xét nghiệm, yêu cầu nào sau đây là đúng theo tiêu chuẩn?\n",
      "Error encoding text 'Khi lựa chọn, vận hành và bảo dưỡng thiết bị phòng xét nghiệm, yêu cầu nào sau đây là đúng theo tiêu chuẩn?': Input Khi lựa chọn, vận hành và bảo dưỡng thiết bị phòng xét nghiệm, yêu cầu nào sau đây là đúng theo tiêu chuẩn? is too long for context length 77\n",
      "A\n",
      "Processing question 39: Nội dung chính của phần tiêu chuẩn trong tài liệu Public008 là gì?\n",
      "B\n",
      "Processing question 40: Nếu phòng xét nghiệm có 500 mẫu xét nghiệm trong tháng, trong đó có 25 mẫu bị từ chối, tỷ lệ từ chối mẫu là bao nhiêu?\n",
      "Error encoding text 'Nếu phòng xét nghiệm có 500 mẫu xét nghiệm trong tháng, trong đó có 25 mẫu bị từ chối, tỷ lệ từ chối mẫu là bao nhiêu?': Input Nếu phòng xét nghiệm có 500 mẫu xét nghiệm trong tháng, trong đó có 25 mẫu bị từ chối, tỷ lệ từ chối mẫu là bao nhiêu? is too long for context length 77\n",
      "B\n",
      "Processing question 41: Học phần Những nguyên lý cơ bản của Chủ nghĩa Mác – Lênin thuộc khối kiến thức nào?\n",
      "A\n",
      "Processing question 42: Học phần Nhập môn ngành CNTT trang bị cho sinh viên những kỹ năng nào ngoài kiến thức chuyên ngành?\n",
      "C\n",
      "Processing question 43: Học phần nào vừa giúp sinh viên năm nhất làm quen với môi trường đại học và kiến thức cơ bản ngành CNTT, vừa rèn luyện các kỹ năng mềm và chuẩn mực đạo đức cần thiết để trở thành kỹ sư công nghệ thông tin?\n",
      "Error encoding text 'Học phần nào vừa giúp sinh viên năm nhất làm quen với môi trường đại học và kiến thức cơ bản ngành CNTT, vừa rèn luyện các kỹ năng mềm và chuẩn mực đạo đức cần thiết để trở thành kỹ sư công nghệ thông tin?': Input Học phần nào vừa giúp sinh viên năm nhất làm quen với môi trường đại học và kiến thức cơ bản ngành CNTT, vừa rèn luyện các kỹ năng mềm và chuẩn mực đạo đức cần thiết để trở thành kỹ sư công nghệ thông tin? is too long for context length 77\n",
      "C\n",
      "Processing question 44: Nội dung chính của tài liệu Public009 là gì?\n",
      "C\n",
      "Processing question 45: Nếu một học phần có cấu trúc 3(2:1:6) thì số tiết lý thuyết, thực hành và tự học lần lượt là bao nhiêu?\n",
      "Error encoding text 'Nếu một học phần có cấu trúc 3(2:1:6) thì số tiết lý thuyết, thực hành và tự học lần lượt là bao nhiêu?': Input Nếu một học phần có cấu trúc 3(2:1:6) thì số tiết lý thuyết, thực hành và tự học lần lượt là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 46: Theo tiêu chuẩn ISO 15189:2022, việc lưu giữ hồ sơ phòng xét nghiệm nhằm mục đích chính nào?\n",
      "C\n",
      "Processing question 47: Khi xảy ra sự không phù hợp, hành động đầu tiên mà phòng xét nghiệm phải thực hiện theo ISO 15189:2022 là gì?\n",
      "Error encoding text 'Khi xảy ra sự không phù hợp, hành động đầu tiên mà phòng xét nghiệm phải thực hiện theo ISO 15189:2022 là gì?': Input Khi xảy ra sự không phù hợp, hành động đầu tiên mà phòng xét nghiệm phải thực hiện theo ISO 15189:2022 là gì? is too long for context length 77\n",
      "A\n",
      "Processing question 48: Theo hướng dẫn về kiểm soát hồ sơ, phòng xét nghiệm phải đảm bảo điều gì khi sửa đổi hồ sơ?\n",
      "Error encoding text 'Theo hướng dẫn về kiểm soát hồ sơ, phòng xét nghiệm phải đảm bảo điều gì khi sửa đổi hồ sơ?': Input Theo hướng dẫn về kiểm soát hồ sơ, phòng xét nghiệm phải đảm bảo điều gì khi sửa đổi hồ sơ? is too long for context length 77\n",
      "A\n",
      "Processing question 49: Nội dung chính của phần 8 trong tiêu chuẩn ISO 15189:2022 là gì?\n",
      "C\n",
      "Processing question 50: Nếu phòng xét nghiệm thiết lập cấu trúc quản lý 5 mục tiêu và mỗi mục tiêu yêu cầu ít nhất 2 hành động cải tiến, tổng số hành động tối thiểu là bao nhiêu?\n",
      "Error encoding text 'Nếu phòng xét nghiệm thiết lập cấu trúc quản lý 5 mục tiêu và mỗi mục tiêu yêu cầu ít nhất 2 hành động cải tiến, tổng số hành động tối thiểu là bao nhiêu?': Input Nếu phòng xét nghiệm thiết lập cấu trúc quản lý 5 mục tiêu và mỗi mục tiêu yêu cầu ít nhất 2 hành động cải tiến, tổng số hành động tối thiểu là bao nhiêu? is too long for context length 77\n",
      "D\n",
      "Processing question 51: Mạng GAN (Global Area Network) là gì?\n",
      "C\n",
      "Processing question 52: Thành phần nào có chức năng giao tiếp giữa máy tính và đường truyền trong mạng máy tính?\n",
      "B\n",
      "Processing question 53: Mạng máy tính được phân loại theo những tiêu chí nào và Internet ban đầu ra đời từ mục đích gì?\n",
      "A\n",
      "Processing question 54: Nội dung chính của tài liệu Public011 là gì?\n",
      "D\n",
      "Processing question 55: Nếu một mạng LAN có bán kính 500m và kết nối 200 máy tính trong một tòa nhà, thì mạng này thuộc loại nào?\n",
      "Error encoding text 'Nếu một mạng LAN có bán kính 500m và kết nối 200 máy tính trong một tòa nhà, thì mạng này thuộc loại nào?': Input Nếu một mạng LAN có bán kính 500m và kết nối 200 máy tính trong một tòa nhà, thì mạng này thuộc loại nào? is too long for context length 77\n",
      "A\n",
      "Processing question 56: Hệ điều hành có nhiệm vụ gì?\n",
      "B\n",
      "Processing question 57: Theo tài liệu, ký hiệu đại diện * trong tên tệp có ý nghĩa gì?\n",
      "C\n",
      "Processing question 58: Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự?\n",
      "Error encoding text 'Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự?': Input Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự? is too long for context length 77\n",
      "A\n",
      "Processing question 59: Nội dung chính của tài liệu Public012 là gì?\n",
      "D\n",
      "Processing question 60: Nếu Windows XP quản lý cho phép đặt tên tập tin dài tối đa 255 ký tự, còn MS-DOS chỉ cho phép tối đa 8 ký tự, thì Windows XP dài hơn bao nhiêu ký tự?\n",
      "Error encoding text 'Nếu Windows XP quản lý cho phép đặt tên tập tin dài tối đa 255 ký tự, còn MS-DOS chỉ cho phép tối đa 8 ký tự, thì Windows XP dài hơn bao nhiêu ký tự?': Input Nếu Windows XP quản lý cho phép đặt tên tập tin dài tối đa 255 ký tự, còn MS-DOS chỉ cho phép tối đa 8 ký tự, thì Windows XP dài hơn bao nhiêu ký tự? is too long for context length 77\n",
      "C\n",
      "Processing question 61: Thế hệ máy tính điện tử nào sử dụng bóng đèn điện tử chân không?\n",
      "A\n",
      "Processing question 62: Thuật ngữ “Tin học” (Informatics) lần đầu tiên được đề xuất bởi ai?\n",
      "B\n",
      "Processing question 63: Thông tin khác dữ liệu ở điểm nào và quá trình xử lý thông tin theo máy tính gồm những bước nào?\n",
      "A\n",
      "Processing question 64: Nội dung chính của tài liệu Public013 là gì?\n",
      "B\n",
      "Processing question 65: Nếu một máy tính thế hệ 2 có tốc độ trung bình 50.000 phép tính/giây, thì nó nhanh gấp bao nhiêu lần so với máy thế hệ 1 tốc độ trung bình 1.000 phép tính/giây?\n",
      "Error encoding text 'Nếu một máy tính thế hệ 2 có tốc độ trung bình 50.000 phép tính/giây, thì nó nhanh gấp bao nhiêu lần so với máy thế hệ 1 tốc độ trung bình 1.000 phép tính/giây?': Input Nếu một máy tính thế hệ 2 có tốc độ trung bình 50.000 phép tính/giây, thì nó nhanh gấp bao nhiêu lần so với máy thế hệ 1 tốc độ trung bình 1.000 phép tính/giây? is too long for context length 77\n",
      "C\n",
      "Processing question 66: Bit là viết tắt của từ gì?\n",
      "A\n",
      "Processing question 67: Trong hệ đếm thập lục phân, ký tự “F” biểu diễn giá trị thập phân nào?\n",
      "C\n",
      "Processing question 68: Trong máy tính, mọi dữ liệu được biểu diễn dưới dạng gì và đơn vị thông tin nhỏ nhất là gì?\n",
      "Error encoding text 'Trong máy tính, mọi dữ liệu được biểu diễn dưới dạng gì và đơn vị thông tin nhỏ nhất là gì?': Input Trong máy tính, mọi dữ liệu được biểu diễn dưới dạng gì và đơn vị thông tin nhỏ nhất là gì? is too long for context length 77\n",
      "B\n",
      "Processing question 69: Nội dung chính của tài liệu Public014 là gì?\n",
      "D\n",
      "Processing question 70: Nếu dùng 8 bit để biểu diễn số nguyên không dấu, giá trị lớn nhất có thể biểu diễn là bao nhiêu?\n",
      "Error encoding text 'Nếu dùng 8 bit để biểu diễn số nguyên không dấu, giá trị lớn nhất có thể biểu diễn là bao nhiêu?': Input Nếu dùng 8 bit để biểu diễn số nguyên không dấu, giá trị lớn nhất có thể biểu diễn là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 71: Khối nào trong CPU có nhiệm vụ thực hiện các phép tính số học và logic?\n",
      "B\n",
      "Processing question 72: Bộ nhớ nào lưu trữ chương trình hệ thống và không bị mất dữ liệu khi tắt máy?\n",
      "A\n",
      "Processing question 73: CPU gồm những bộ phận chính nào và bộ nhớ chính của máy tính được chia thành những loại nào?\n",
      "B\n",
      "Processing question 74: Nội dung chính của tài liệu Public015 là gì?\n",
      "D\n",
      "Processing question 75: Nếu một CPU có 36 bit địa chỉ, dung lượng tối đa của bộ nhớ chính mà nó quản lý được là bao nhiêu?\n",
      "Error encoding text 'Nếu một CPU có 36 bit địa chỉ, dung lượng tối đa của bộ nhớ chính mà nó quản lý được là bao nhiêu?': Input Nếu một CPU có 36 bit địa chỉ, dung lượng tối đa của bộ nhớ chính mà nó quản lý được là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 76: Tiêu chuẩn TCVN 9395:2012 áp dụng cho loại cọc nào?\n",
      "B\n",
      "Processing question 77: Dung dịch khoan bentonite có vai trò chính gì trong thi công cọc khoan nhồi?\n",
      "A\n",
      "Processing question 78: Theo TCVN 9395:2012, tiêu chuẩn này áp dụng cho loại cọc nào và từ đường kính bao nhiêu trở lên?\n",
      "C\n",
      "Processing question 79: Nội dung chính của tiêu chuẩn TCVN 9395:2012 là gì?\n",
      "C\n",
      "Processing question 80: Nếu trong quá trình khoan, cao độ dung dịch khoan phải luôn cao hơn mực nước ngầm ít nhất 1,5 m, giả sử mực nước ngầm ở -10 m thì cao độ dung dịch khoan tối thiểu phải đạt bao nhiêu?\n",
      "Error encoding text 'Nếu trong quá trình khoan, cao độ dung dịch khoan phải luôn cao hơn mực nước ngầm ít nhất 1,5 m, giả sử mực nước ngầm ở -10 m thì cao độ dung dịch khoan tối thiểu phải đạt bao nhiêu?': Input Nếu trong quá trình khoan, cao độ dung dịch khoan phải luôn cao hơn mực nước ngầm ít nhất 1,5 m, giả sử mực nước ngầm ở -10 m thì cao độ dung dịch khoan tối thiểu phải đạt bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 81: Theo TCVN 5574:2018, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện dựa trên những trạng thái giới hạn nào?\n",
      "Error encoding text 'Theo TCVN 5574:2018, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện dựa trên những trạng thái giới hạn nào?': Input Theo TCVN 5574:2018, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện dựa trên những trạng thái giới hạn nào? is too long for context length 77\n",
      "B\n",
      "Processing question 82: Các loại bê tông nào được phép sử dụng khi thiết kế kết cấu theo TCVN 5574:2018?\n",
      "A\n",
      "Processing question 83: Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình?\n",
      "Error encoding text 'Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình?': Input Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được thực hiện theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình? is too long for context length 77\n",
      "A\n",
      "Processing question 84: Nội dung chính của tiêu chuẩn TCVN 5574:2018 là gì?\n",
      "B\n",
      "Processing question 85: Nếu một dầm bê tông cốt thép có nhịp 6 m, theo TCVN 5574:2018 độ võng tối đa cho phép là 1/150 nhịp, giá trị võng lớn nhất cho phép là bao nhiêu?\n",
      "Error encoding text 'Nếu một dầm bê tông cốt thép có nhịp 6 m, theo TCVN 5574:2018 độ võng tối đa cho phép là 1/150 nhịp, giá trị võng lớn nhất cho phép là bao nhiêu?': Input Nếu một dầm bê tông cốt thép có nhịp 6 m, theo TCVN 5574:2018 độ võng tối đa cho phép là 1/150 nhịp, giá trị võng lớn nhất cho phép là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 86: Tiêu chuẩn TCVN 5574:2018 áp dụng cho những loại bê tông nào?\n",
      "D\n",
      "Processing question 87: Tiêu chuẩn này không áp dụng để thiết kế loại kết cấu nào sau đây?\n",
      "C\n",
      "Processing question 88: Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được tiến hành theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình?\n",
      "Error encoding text 'Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được tiến hành theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình?': Input Theo TCVN 9379:2012, tính toán kết cấu bê tông và bê tông cốt thép cần được tiến hành theo những trạng thái giới hạn nào và phải đảm bảo điều gì trong suốt thời hạn sử dụng công trình? is too long for context length 77\n",
      "A\n",
      "Processing question 89: Nội dung chính của phần yêu cầu chung đối với kết cấu bê tông và bê tông cốt thép trong TCVN 5574:2018 là gì?\n",
      "Error encoding text 'Nội dung chính của phần yêu cầu chung đối với kết cấu bê tông và bê tông cốt thép trong TCVN 5574:2018 là gì?': Input Nội dung chính của phần yêu cầu chung đối với kết cấu bê tông và bê tông cốt thép trong TCVN 5574:2018 là gì? is too long for context length 77\n",
      "B\n",
      "Processing question 90: Nếu một cấu kiện bê tông làm việc trong môi trường xâm thực, theo TCVN 5574:2018, cần đảm bảo thêm yêu cầu gì ngoài an toàn và sử dụng bình thường?\n",
      "Error encoding text 'Nếu một cấu kiện bê tông làm việc trong môi trường xâm thực, theo TCVN 5574:2018, cần đảm bảo thêm yêu cầu gì ngoài an toàn và sử dụng bình thường?': Input Nếu một cấu kiện bê tông làm việc trong môi trường xâm thực, theo TCVN 5574:2018, cần đảm bảo thêm yêu cầu gì ngoài an toàn và sử dụng bình thường? is too long for context length 77\n",
      "C\n",
      "Processing question 91: Hệ thống chống sét theo TCVN 9385:2012 bao gồm mấy phần chính?\n",
      "D\n",
      "Processing question 92: Bộ phận nào trong hệ thống chống sét có nhiệm vụ thu sét trực tiếp?\n",
      "B\n",
      "Processing question 93: Quốc gia nào là nước đầu tiên công bố Kế hoạch chiến lược trí tuệ nhân tạo quốc gia và vào năm nào?\n",
      "Error encoding text 'Quốc gia nào là nước đầu tiên công bố Kế hoạch chiến lược trí tuệ nhân tạo quốc gia và vào năm nào?': Input Quốc gia nào là nước đầu tiên công bố Kế hoạch chiến lược trí tuệ nhân tạo quốc gia và vào năm nào? is too long for context length 77\n",
      "B\n",
      "Processing question 94: Nội dung chính của TCVN 9385:2012 là gì?\n",
      "D\n",
      "Processing question 95: Một công trình cao 30 m cần bảo vệ chống sét trực tiếp. Theo bán kính bảo vệ của kim thu sét (r = 1,5h), bán kính bảo vệ tối đa là bao nhiêu?\n",
      "Error encoding text 'Một công trình cao 30 m cần bảo vệ chống sét trực tiếp. Theo bán kính bảo vệ của kim thu sét (r = 1,5h), bán kính bảo vệ tối đa là bao nhiêu?': Input Một công trình cao 30 m cần bảo vệ chống sét trực tiếp. Theo bán kính bảo vệ của kim thu sét (r = 1,5h), bán kính bảo vệ tối đa là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 96: Chiều dày màng khô của lớp phủ chống cháy được xác định bằng cách nào?\n",
      "B\n",
      "Processing question 97: Loại đầu đo nhiệt nào được ưu tiên sử dụng trong thử nghiệm cấu kiện thép?\n",
      "C\n",
      "Processing question 98: Theo quy định, chiều dày màng khô của vật liệu bảo vệ được đo bằng nguyên tắc nào và loại đầu đo nhiệt nào được ưu tiên sử dụng khi thử nghiệm trên cấu kiện thép?\n",
      "Error encoding text 'Theo quy định, chiều dày màng khô của vật liệu bảo vệ được đo bằng nguyên tắc nào và loại đầu đo nhiệt nào được ưu tiên sử dụng khi thử nghiệm trên cấu kiện thép?': Input Theo quy định, chiều dày màng khô của vật liệu bảo vệ được đo bằng nguyên tắc nào và loại đầu đo nhiệt nào được ưu tiên sử dụng khi thử nghiệm trên cấu kiện thép? is too long for context length 77\n",
      "C\n",
      "Processing question 99: Nội dung chính của tài liệu là gì?\n",
      "C\n",
      "Processing question 100: Theo quy định, cần bao nhiêu phép đo chiều dày tối thiểu trên dầm chịu tải?\n",
      "C\n",
      "Processing question 101: Bộ mã chuẩn nào đã được chọn cho tiếng Việt trong CNTT?\n",
      "B\n",
      "Processing question 102: Trong xử lý ngôn ngữ, bài toán nào có mục tiêu chuyển văn bản thành tiếng nói?\n",
      "C\n",
      "Processing question 103: Khi đo chiều dày màng khô của vật liệu bảo vệ, phòng thử nghiệm sử dụng nguyên tắc nào và tối thiểu đường kính vỏ bọc của đầu đo nhiệt ưu tiên là bao nhiêu?\n",
      "Error encoding text 'Khi đo chiều dày màng khô của vật liệu bảo vệ, phòng thử nghiệm sử dụng nguyên tắc nào và tối thiểu đường kính vỏ bọc của đầu đo nhiệt ưu tiên là bao nhiêu?': Input Khi đo chiều dày màng khô của vật liệu bảo vệ, phòng thử nghiệm sử dụng nguyên tắc nào và tối thiểu đường kính vỏ bọc của đầu đo nhiệt ưu tiên là bao nhiêu? is too long for context length 77\n",
      "No match found\n",
      "Processing question 104: Nội dung chính của tài liệu Public021 là gì?\n",
      "B\n",
      "Processing question 105: Theo đánh giá, hiện có bao nhiêu phần trăm dữ liệu không cấu trúc trong tổng lượng dữ liệu của loài người?\n",
      "Error encoding text 'Theo đánh giá, hiện có bao nhiêu phần trăm dữ liệu không cấu trúc trong tổng lượng dữ liệu của loài người?': Input Theo đánh giá, hiện có bao nhiêu phần trăm dữ liệu không cấu trúc trong tổng lượng dữ liệu của loài người? is too long for context length 77\n",
      "C\n",
      "Processing question 106: Tiêu chuẩn TCVN xxxx:202x được xây dựng dựa trên tiêu chuẩn quốc tế nào?\n",
      "A\n",
      "Processing question 107: Chiều dày lớp bảo vệ chịu lửa được định nghĩa như thế nào?\n",
      "C\n",
      "Processing question 108: Theo tiêu chuẩn, các thử nghiệm chịu lửa được áp dụng cho những loại tiết diện thép nào và không áp dụng cho loại nào?\n",
      "Error encoding text 'Theo tiêu chuẩn, các thử nghiệm chịu lửa được áp dụng cho những loại tiết diện thép nào và không áp dụng cho loại nào?': Input Theo tiêu chuẩn, các thử nghiệm chịu lửa được áp dụng cho những loại tiết diện thép nào và không áp dụng cho loại nào? is too long for context length 77\n",
      "C\n",
      "Processing question 109: Nội dung chính của tiêu chuẩn TCVN xxxx:202x là gì?\n",
      "B\n",
      "Processing question 110: Theo quy định, mẫu thử nghiệm dầm chịu tải phải chịu tải trọng bằng bao nhiêu phần trăm sức kháng mô men thiết kế?\n",
      "Error encoding text 'Theo quy định, mẫu thử nghiệm dầm chịu tải phải chịu tải trọng bằng bao nhiêu phần trăm sức kháng mô men thiết kế?': Input Theo quy định, mẫu thử nghiệm dầm chịu tải phải chịu tải trọng bằng bao nhiêu phần trăm sức kháng mô men thiết kế? is too long for context length 77\n",
      "C\n",
      "Processing question 111: Chiều dày vật liệu bọc bảo vệ dạng bản hoặc tấm được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình?\n",
      "Error encoding text 'Chiều dày vật liệu bọc bảo vệ dạng bản hoặc tấm được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình?': Input Chiều dày vật liệu bọc bảo vệ dạng bản hoặc tấm được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình? is too long for context length 77\n",
      "B\n",
      "Processing question 112: Đối với lớp phủ dạng phản ứng, độ dày trung bình được xác định như thế nào?\n",
      "Error encoding text 'Đối với lớp phủ dạng phản ứng, độ dày trung bình được xác định như thế nào?': Input Đối với lớp phủ dạng phản ứng, độ dày trung bình được xác định như thế nào? is too long for context length 77\n",
      "C\n",
      "Processing question 113: Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự?\n",
      "Error encoding text 'Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự?': Input Hệ điều hành có những nhiệm vụ chính nào và phiên bản Windows nào cho phép đặt tên tệp dài tới 255 ký tự? is too long for context length 77\n",
      "A\n",
      "Processing question 114: Nội dung chính của tài liệu Public023 là gì?\n",
      "A\n",
      "Processing question 115: Khối lượng riêng của vật liệu bảo vệ dạng thụ động được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình?\n",
      "Error encoding text 'Khối lượng riêng của vật liệu bảo vệ dạng thụ động được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình?': Input Khối lượng riêng của vật liệu bảo vệ dạng thụ động được phép sai lệch tối đa bao nhiêu % so với giá trị trung bình? is too long for context length 77\n",
      "D\n",
      "Processing question 116: Theo tài liệu, thực phẩm được định nghĩa là gì?\n",
      "B\n",
      "Processing question 117: Thực phẩm giàu protein thường có trong nhóm nguyên liệu nào?\n",
      "C\n",
      "Processing question 118: Thực phẩm là gì? Thực phẩm chức năng dùng chủ yếu để làm gì?\n",
      "B\n",
      "Processing question 119: Nội dung chính của phần “Khái quát về thực phẩm và công nghệ thực phẩm” là gì?\n",
      "A\n",
      "Processing question 120: Nếu một người tiêu dùng mua 100g bánh mì (giàu glucid ~50%) và 100g cá (giàu protein ~20%), thì lượng glucid và protein người đó nạp vào lần lượt là bao nhiêu gam?\n",
      "Error encoding text 'Nếu một người tiêu dùng mua 100g bánh mì (giàu glucid ~50%) và 100g cá (giàu protein ~20%), thì lượng glucid và protein người đó nạp vào lần lượt là bao nhiêu gam?': Input Nếu một người tiêu dùng mua 100g bánh mì (giàu glucid ~50%) và 100g cá (giàu protein ~20%), thì lượng glucid và protein người đó nạp vào lần lượt là bao nhiêu gam? is too long for context length 77\n",
      "C\n",
      "Processing question 121: Chiếu xạ thực phẩm được định nghĩa là gì?\n",
      "B\n",
      "Processing question 122: Tia bức xạ nào hiện nay được sử dụng phổ biến trong công nghiệp thực phẩm?\n",
      "C\n",
      "Processing question 123: Chiếu xạ thực phẩm về mặt cơ sở khoa học là gì? Và mục đích công nghệ chủ yếu hiện nay của chiếu xạ thực phẩm là gì?\n",
      "Error encoding text 'Chiếu xạ thực phẩm về mặt cơ sở khoa học là gì? Và mục đích công nghệ chủ yếu hiện nay của chiếu xạ thực phẩm là gì?': Input Chiếu xạ thực phẩm về mặt cơ sở khoa học là gì? Và mục đích công nghệ chủ yếu hiện nay của chiếu xạ thực phẩm là gì? is too long for context length 77\n",
      "D\n",
      "Processing question 124: Nội dung chính của phần “Chiếu xạ trong công nghiệp thực phẩm” là gì?\n",
      "A\n",
      "Processing question 125: Nếu một loại trái cây được xử lý bằng liều chiếu xạ 2 kGy, trong khi mức 1 kGy không làm mất vitamin C còn mức 2–4 kGy làm giảm mạnh vitamin C, thì loại trái cây đó có nguy cơ bị giảm giá trị dinh dưỡng như thế nào?\n",
      "Error encoding text 'Nếu một loại trái cây được xử lý bằng liều chiếu xạ 2 kGy, trong khi mức 1 kGy không làm mất vitamin C còn mức 2–4 kGy làm giảm mạnh vitamin C, thì loại trái cây đó có nguy cơ bị giảm giá trị dinh dưỡng như thế nào?': Input Nếu một loại trái cây được xử lý bằng liều chiếu xạ 2 kGy, trong khi mức 1 kGy không làm mất vitamin C còn mức 2–4 kGy làm giảm mạnh vitamin C, thì loại trái cây đó có nguy cơ bị giảm giá trị dinh dưỡng như thế nào? is too long for context length 77\n",
      "C\n",
      "Processing question 126: Xơ dệt được phân loại theo nguồn gốc thành mấy nhóm chính?\n",
      "C\n",
      "Processing question 127: Thành phần chính của xơ len là gì?\n",
      "C\n",
      "Processing question 128: Vật liệu dệt là gì? Và chúng được phân loại chủ yếu dựa theo tiêu chí nào?\n",
      "D\n",
      "Processing question 129: Nội dung chính của chương 1 trong tài liệu là gì?\n",
      "D\n",
      "Processing question 130: Nếu một sợi có chiều dài 1000 m và khối lượng 20 g thì chỉ số Tex của sợi đó bằng bao nhiêu?\n",
      "Error encoding text 'Nếu một sợi có chiều dài 1000 m và khối lượng 20 g thì chỉ số Tex của sợi đó bằng bao nhiêu?': Input Nếu một sợi có chiều dài 1000 m và khối lượng 20 g thì chỉ số Tex của sợi đó bằng bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 131: Thành phần chính của xơ bông là gì?\n",
      "B\n",
      "Processing question 132: Nhiệt độ chuyển mềm của len thường nằm trong khoảng nào?\n",
      "C\n",
      "Processing question 133: Xenlulô là gì và vải sợi gốc xenlulô có ưu điểm gì?\n",
      "C\n",
      "Processing question 134: Nội dung chính của tài liệu Public027 là gì?\n",
      "D\n",
      "Processing question 135: Nếu sợi bông có độ ẩm hoàn toàn khô là 8 g, khi hút ẩm đạt khối lượng 8,8 g thì độ ẩm tương đối của sợi là bao nhiêu?\n",
      "Error encoding text 'Nếu sợi bông có độ ẩm hoàn toàn khô là 8 g, khi hút ẩm đạt khối lượng 8,8 g thì độ ẩm tương đối của sợi là bao nhiêu?': Input Nếu sợi bông có độ ẩm hoàn toàn khô là 8 g, khi hút ẩm đạt khối lượng 8,8 g thì độ ẩm tương đối của sợi là bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 136: Ai là những nhà khoa học được ghi nhận phát minh ra transistor lưỡng cực vào năm 1947?\n",
      "C\n",
      "Processing question 137: Transistor NPN có các cực được sắp xếp như thế nào?\n",
      "B\n",
      "Processing question 138: Transistor được tạo thành từ mấy lớp bán dẫn và ba người nào được ghi nhận là những nhà phát minh ra nó?\n",
      "Error encoding text 'Transistor được tạo thành từ mấy lớp bán dẫn và ba người nào được ghi nhận là những nhà phát minh ra nó?': Input Transistor được tạo thành từ mấy lớp bán dẫn và ba người nào được ghi nhận là những nhà phát minh ra nó? is too long for context length 77\n",
      "A\n",
      "Processing question 139: Nội dung chính của tài liệu Public028 là gì?\n",
      "B\n",
      "Processing question 140: Nếu bộ phát (Emitter) bị pha tạp nặng, Base pha tạp nhẹ và Collector pha tạp vừa phải, thì vùng nghèo kiệt sẽ mở rộng nhiều hơn về phía nào?\n",
      "Error encoding text 'Nếu bộ phát (Emitter) bị pha tạp nặng, Base pha tạp nhẹ và Collector pha tạp vừa phải, thì vùng nghèo kiệt sẽ mở rộng nhiều hơn về phía nào?': Input Nếu bộ phát (Emitter) bị pha tạp nặng, Base pha tạp nhẹ và Collector pha tạp vừa phải, thì vùng nghèo kiệt sẽ mở rộng nhiều hơn về phía nào? is too long for context length 77\n",
      "A\n",
      "Processing question 141: Vật liệu nào phổ biến nhất được sử dụng làm chất bán dẫn cơ bản?\n",
      "A\n",
      "Processing question 142: Quá trình thêm tạp chất vào chất bán dẫn để cải thiện tính dẫn điện gọi là gì?\n",
      "B\n",
      "Processing question 143: Chất bán dẫn tinh khiết là gì và hiện tượng pha tạp (doping) có tác dụng gì?\n",
      "A\n",
      "Processing question 144: Nội dung chính của tài liệu Public029 là gì?\n",
      "B\n",
      "Processing question 145: Nếu một tinh thể silicon có tỷ lệ doping là 1 nguyên tử tạp chất trên 10 triệu nguyên tử Si, thì khi thêm 100 nguyên tử tạp chất, số nguyên tử Si xấp xỉ bao nhiêu?\n",
      "Error encoding text 'Nếu một tinh thể silicon có tỷ lệ doping là 1 nguyên tử tạp chất trên 10 triệu nguyên tử Si, thì khi thêm 100 nguyên tử tạp chất, số nguyên tử Si xấp xỉ bao nhiêu?': Input Nếu một tinh thể silicon có tỷ lệ doping là 1 nguyên tử tạp chất trên 10 triệu nguyên tử Si, thì khi thêm 100 nguyên tử tạp chất, số nguyên tử Si xấp xỉ bao nhiêu? is too long for context length 77\n",
      "C\n",
      "Processing question 146: Đơn vị đo điện dung của tụ điện là gì?\n",
      "A\n",
      "Processing question 147: Hằng số điện môi ε₀ trong chân không có giá trị bao nhiêu?\n",
      "B\n",
      "Processing question 148: Tụ điện là gì và điện dung của tụ được tính theo công thức nào?\n",
      "A\n",
      "Processing question 149: Nội dung chính của tài liệu Public030 là gì?\n",
      "No match found\n",
      "Processing question 150: Một tụ điện phẳng có A = 10 m², d = 5 m, điện môi là không khí (εr = 1). Hãy tính điện dung C.\n",
      "D\n",
      "Processing question 151: Đơn vị đo điện trở là gì?\n",
      "A\n",
      "Processing question 152: Ký hiệu điện trở theo tiêu chuẩn IEC có dạng nào?\n",
      "B\n",
      "Processing question 153: Điện trở là gì và tại sao được gọi là linh kiện thụ động?\n",
      "B\n",
      "Processing question 154: Nội dung chính của tài liệu Public031 là gì?\n",
      "A\n",
      "Processing question 155: Một mạch nối tiếp gồm R1 = 2Ω, R2 = 4Ω, R3 = 6Ω, dòng điện I = 4A. Hãy tính điện áp toàn mạch.\n",
      "Error encoding text 'Một mạch nối tiếp gồm R1 = 2Ω, R2 = 4Ω, R3 = 6Ω, dòng điện I = 4A. Hãy tính điện áp toàn mạch.': Input Một mạch nối tiếp gồm R1 = 2Ω, R2 = 4Ω, R3 = 6Ω, dòng điện I = 4A. Hãy tính điện áp toàn mạch. is too long for context length 77\n",
      "C\n",
      "Processing question 156: Nguồn điện nào thường tạo ra điện áp một chiều (DC)?\n",
      "A\n",
      "Processing question 157: Định luật Ohm được phát biểu như thế nào?\n",
      "B\n",
      "Processing question 158: Dòng điện một chiều (DC) là gì và định luật Ohm liên quan như thế nào?\n",
      "B\n",
      "Processing question 159: Nội dung chính của tài liệu Public032 là gì?\n",
      "B\n",
      "Processing question 160: Một mạch có điện áp 12V và điện trở 6Ω. Hãy tính dòng điện chạy qua mạch theo định luật Ohm.\n",
      "Error encoding text 'Một mạch có điện áp 12V và điện trở 6Ω. Hãy tính dòng điện chạy qua mạch theo định luật Ohm.': Input Một mạch có điện áp 12V và điện trở 6Ω. Hãy tính dòng điện chạy qua mạch theo định luật Ohm. is too long for context length 77\n",
      "A\n",
      "Processing question 161: Ai là người phát minh ra pin điện đầu tiên vào năm 1800?\n",
      "B\n",
      "Processing question 162: Dòng điện tử trong thực tế chảy theo chiều nào?\n",
      "C\n",
      "Processing question 163: Nguồn gốc dòng điện và hai giả thuyết về chiều dòng điện là gì?\n",
      "B\n",
      "Processing question 164: Nội dung chính của phần “Giới thiệu về điện” trong tài liệu Public033 là gì?\n",
      "D\n",
      "Processing question 165: Nếu một dầm dây dẫn có dòng điện 2000 mA chạy qua, giá trị này tương ứng với bao nhiêu ampe?\n",
      "Error encoding text 'Nếu một dầm dây dẫn có dòng điện 2000 mA chạy qua, giá trị này tương ứng với bao nhiêu ampe?': Input Nếu một dầm dây dẫn có dòng điện 2000 mA chạy qua, giá trị này tương ứng với bao nhiêu ampe? is too long for context length 77\n",
      "C\n",
      "Processing question 166: Photodiode hoạt động hiệu quả nhất khi được phân cực như thế nào?\n",
      "A\n",
      "Processing question 167: Ai là người đầu tiên đề xuất ý tưởng về phototransistor?\n",
      "C\n",
      "Processing question 168: Photodiode hoạt động như thế nào và khác gì với phototransistor?\n",
      "A\n",
      "Processing question 169: Nội dung chính của tài liệu “Linh kiện quang điện tử” là gì?\n",
      "B\n",
      "Processing question 170: Một photodiode PIN cho dòng điện 1 µA trong điều kiện chiếu sáng phòng. Một phototransistor cùng điều kiện có dòng lớn hơn khoảng bao nhiêu lần?\n",
      "Error encoding text 'Một photodiode PIN cho dòng điện 1 µA trong điều kiện chiếu sáng phòng. Một phototransistor cùng điều kiện có dòng lớn hơn khoảng bao nhiêu lần?': Input Một photodiode PIN cho dòng điện 1 µA trong điều kiện chiếu sáng phòng. Một phototransistor cùng điều kiện có dòng lớn hơn khoảng bao nhiêu lần? is too long for context length 77\n",
      "D\n",
      "Processing question 171: MAE loss còn có tên khác là gì\n",
      "A\n",
      "Processing question 172: Điều gì xảy ra nếu learning rate quá nhỏ\n",
      "C\n",
      "Processing question 173: Trong bối cảnh linear regression đơn biến, mô hình được biểu diễn ra sao và mục tiêu của bài toán khi được mô hình hóa là gì?\n",
      "Error encoding text 'Trong bối cảnh linear regression đơn biến, mô hình được biểu diễn ra sao và mục tiêu của bài toán khi được mô hình hóa là gì?': Input Trong bối cảnh linear regression đơn biến, mô hình được biểu diễn ra sao và mục tiêu của bài toán khi được mô hình hóa là gì? is too long for context length 77\n",
      "B\n",
      "Processing question 174: Yếu tố nào giúp mô hình hóa bài toán linear regression\n",
      "A\n",
      "Processing question 175: Một trình tối ưu linear regression bỗng dưng ghi nhận cost function tăng. Đâu là hành động hợp lý trong các hành động dưới ở lượt chạy tiếp theo?\n",
      "Error encoding text 'Một trình tối ưu linear regression bỗng dưng ghi nhận cost function tăng. Đâu là hành động hợp lý trong các hành động dưới ở lượt chạy tiếp theo?': Input Một trình tối ưu linear regression bỗng dưng ghi nhận cost function tăng. Đâu là hành động hợp lý trong các hành động dưới ở lượt chạy tiếp theo? is too long for context length 77\n",
      "C\n",
      "Processing question 176: Đâu không phải một ứng dụng của Image segmentation được đề cập trong tài liệu?\n",
      "A,B,C\n",
      "Processing question 177: Mạng U-Net có mấy phần chính?\n",
      "B\n",
      "Processing question 178: Có bao nhiêu loại bài toán segmentation và đó là những loại nào?\n",
      "C\n",
      "Processing question 179: Nhận định nào dưới đây không chính xác với mạng U-Net trong bài toán Image segmentation?\n",
      "A\n",
      "Processing question 180: Xác định padding (p) và stride (s) khi tiến hành transposed convolution với input 4x4, kernel 3x3 để cho ra output 9x9\n",
      "B\n",
      "Processing question 181: Trong ví dụ ở đầu tài liệu, đâu không phải là một mô tả ảnh được giới thiệu?\n",
      "D\n",
      "Processing question 182: Mô hình skip-gram ban đầu có bao nhiêu lớp ẩn (hidden layer)?\n",
      "A\n",
      "Processing question 183: Co-occurrence matrix có tính chất đối xứng gì và kích thước của ma trận này là bao nhiêu (với V là kích thước từ điển)?\n",
      "Error encoding text 'Co-occurrence matrix có tính chất đối xứng gì và kích thước của ma trận này là bao nhiêu (với V là kích thước từ điển)?': Input Co-occurrence matrix có tính chất đối xứng gì và kích thước của ma trận này là bao nhiêu (với V là kích thước từ điển)? is too long for context length 77\n",
      "B\n",
      "Processing question 184: Khẳng định nào dưới đây không đúng với bối cảnh bài toán?\n",
      "B\n",
      "Processing question 185: Vector nào sau đây không thuộc về one-hot encoding?\n",
      "B,C\n",
      "Processing question 186: Đâu không phải một dạng RNN?\n",
      "B\n",
      "Processing question 187: Sinh mô tả ảnh thuộc vào dạng RNN nào?\n",
      "D\n",
      "Processing question 188: Câu output của seq2seq sẽ có thêm mấy token và đó là những token nào?\n",
      "D\n",
      "Processing question 189: Trong bối cảnh dịch máy, đâu là cách hiểu \"sản phẩm trung gian\" phù hợp với seq2seq?\n",
      "D\n",
      "Processing question 190: Khẳng định nào dưới đây là đúng với cơ chế attention?\n",
      "B\n",
      "Processing question 191: Đâu không phải là một ứng dụng của GAN được nêu trong phần đầu tiên của văn bản Public039?\n",
      "Error encoding text 'Đâu không phải là một ứng dụng của GAN được nêu trong phần đầu tiên của văn bản Public039?': Input Đâu không phải là một ứng dụng của GAN được nêu trong phần đầu tiên của văn bản Public039? is too long for context length 77\n",
      "A\n",
      "Processing question 192: GAN là viết tắt của?\n",
      "A\n",
      "Processing question 193: GAN gồm bao nhiêu thành phần mạng và tên gọi của chúng, theo đúng thuật ngữ, là?\n",
      "C\n",
      "Processing question 194: Tóm tắt cách hoạt động của GAN?\n",
      "B\n",
      "Processing question 195: Đâu là một ví dụ được coi là tương đồng với cách thức huấn luyện của GAN?\n",
      "D\n",
      "Processing question 196: Khác biệt về kiến trúc của DCGAN và GAN?\n",
      "B\n",
      "Processing question 197: Input của Generator là?\n",
      "C\n",
      "Processing question 198: Output tương ứng với CIFAR-10 và Fashion-MNIST là?\n",
      "D\n",
      "Processing question 199: Điểm chung giữa DCGAN và Conditional GAN là?\n",
      "B\n",
      "Processing question 200: Đâu là yếu tố tạo nên \"Conditional\" trong Conditional GAN?\n",
      "B\n",
      "Processing question 201: Logistic regression có đầu ra là gì?\n",
      "B\n",
      "Processing question 202: Đâu là công thức của sigmoid?\n",
      "C\n",
      "Processing question 203: Loss function biến thiên ra sao khi output y_i lần lượt là 1 và 0?\n",
      "C\n",
      "Processing question 204: Điểm giống nhau cơ bản của logistic regression và linear regression là gì\n",
      "A\n",
      "Processing question 205: Theo nguyên lý xác suất đã nêu, đâu không phải là một khẳng định hợp lý?\n",
      "C\n",
      "Processing question 206: Mô hình neural network lấy cảm hứng từ?\n",
      "B\n",
      "Processing question 207: Neural network bắt chước toàn bộ cơ chế hoạt động của hệ thần kinh, đúng hay sai?\n",
      "A\n",
      "Processing question 208: Ký hiệu phổ biến cho số đặc trưng trong một điểm dữ liệu và số điểm dữ liệu lần lượt là?\n",
      "Error encoding text 'Ký hiệu phổ biến cho số đặc trưng trong một điểm dữ liệu và số điểm dữ liệu lần lượt là?': Input Ký hiệu phổ biến cho số đặc trưng trong một điểm dữ liệu và số điểm dữ liệu lần lượt là? is too long for context length 77\n",
      "D\n",
      "Processing question 209: Bài toán về toán tử bit nào là minh chứng cho việc cần xây dựng nhiều hơn một lớp ẩn?\n",
      "C\n",
      "Processing question 210: Vì sao lại nên dùng hàm kích hoạt phi tuyến (non-linear activation)?\n",
      "D\n",
      "Processing question 211: Hệ màu RGB biểu diễn tất cả các màu khả kiến dưới dạng tổ hợp của ba màu gì?\n",
      "Error encoding text 'Hệ màu RGB biểu diễn tất cả các màu khả kiến dưới dạng tổ hợp của ba màu gì?': Input Hệ màu RGB biểu diễn tất cả các màu khả kiến dưới dạng tổ hợp của ba màu gì? is too long for context length 77\n",
      "A\n",
      "Processing question 212: Tensor được chuyên dùng để mô tả dữ liệu theo mấy chiều\n",
      "C\n",
      "Processing question 213: Một pixel của ảnh xám có thể nhận giá trị tối thiểu và tối đa lần lượt là?\n",
      "C\n",
      "Processing question 214: Phép tích chập (convolution) gồm ba yếu tố chính là kernel và hai thành phần nào?\n",
      "B\n",
      "Processing question 215: Đâu là giá trị của pixel ảnh xám ứng với pixel ảnh RGB (100, 10, 1)? Biết rằng công thức quy đổi là p = 0.299 * r + 0.587 * g + 0.114 * b (kết quả làm tròn tới hàng đơn vị)\n",
      "Error encoding text 'Đâu là giá trị của pixel ảnh xám ứng với pixel ảnh RGB (100, 10, 1)? Biết rằng công thức quy đổi là p = 0.299 * r + 0.587 * g + 0.114 * b (kết quả làm tròn tới hàng đơn vị)': Input Đâu là giá trị của pixel ảnh xám ứng với pixel ảnh RGB (100, 10, 1)? Biết rằng công thức quy đổi là p = 0.299 * r + 0.587 * g + 0.114 * b (kết quả làm tròn tới hàng đơn vị) is too long for context length 77\n",
      "C\n",
      "Processing question 216: Đâu là vấn đề mà CNN giải quyết tốt hơn so với thiết kế mạng truyền thống?\n",
      "B\n",
      "Processing question 217: Pooling layer được thiết kế để?\n",
      "B\n",
      "Processing question 218: Pooling layer của VGG16 có kích thước ra sao và hàm pool là?\n",
      "C\n",
      "Processing question 219: Tổng quát một CNN sẽ gồm hai phần chính nào sau đây?\n",
      "C\n",
      "Processing question 220: Kết quả average pooling của hình vuông gồm 4 giá trị 15, 20, 30, 45 là?\n",
      "B\n",
      "Processing question 221: Điểm chung của Transfer learning và data augmentation là gì\n",
      "B\n",
      "Processing question 222: Đâu không phải là một hình thức data augmentation cho ảnh?\n",
      "C\n",
      "Processing question 223: Khi tiến hành phân lớp với nhiều hơn hai lớp, có bao nhiêu chiến lược tiếp cận? Hình thức của chúng là?\n",
      "Error encoding text 'Khi tiến hành phân lớp với nhiều hơn hai lớp, có bao nhiêu chiến lược tiếp cận? Hình thức của chúng là?': Input Khi tiến hành phân lớp với nhiều hơn hai lớp, có bao nhiêu chiến lược tiếp cận? Hình thức của chúng là? is too long for context length 77\n",
      "C\n",
      "Processing question 224: Trường hợp nào sau đây được đề xuất sử dụng Finetuning hơn là Feature extractor?\n",
      "I. Dữ liệu lớn, khác dữ liệu pretrain\n",
      "II. Dữ liệu nhỏ, khác dữ liệu pretrain\n",
      "III. Dữ liệu nhỏ, giống dữ liệu pretrain\n",
      "IV. Dữ liệu lớn, giống dữ liệu pretrain\n",
      "Error encoding text 'Trường hợp nào sau đây được đề xuất sử dụng Finetuning hơn là Feature extractor?\n",
      "I. Dữ liệu lớn, khác dữ liệu pretrain\n",
      "II. Dữ liệu nhỏ, khác dữ liệu pretrain\n",
      "III. Dữ liệu nhỏ, giống dữ liệu pretrain\n",
      "IV. Dữ liệu lớn, giống dữ liệu pretrain': Input Trường hợp nào sau đây được đề xuất sử dụng Finetuning hơn là Feature extractor?\n",
      "I. Dữ liệu lớn, khác dữ liệu pretrain\n",
      "II. Dữ liệu nhỏ, khác dữ liệu pretrain\n",
      "III. Dữ liệu nhỏ, giống dữ liệu pretrain\n",
      "IV. Dữ liệu lớn, giống dữ liệu pretrain is too long for context length 77\n",
      "C\n",
      "Processing question 225: Đâu không phải là khẳng định đúng giữa Finetuning và Feature extractor\n",
      "A\n",
      "Processing question 226: Lợi ích chính của vectorization là gì\n",
      "A\n",
      "Processing question 227: Giá trị p trong dropout thể hiện điều gì?\n",
      "No match found\n",
      "Processing question 228: Khái niệm tiếng Việt cho bias và variance là gì?\n",
      "C\n",
      "Processing question 229: Đâu là mục tiêu chính của các phương pháp trong tài liệu Public046?\n",
      "D\n",
      "Processing question 230: Một thuật toán gradient descent lấy ra 32 dữ liệu điểm mỗi lần tính đạo hàm thì thuộc loại gradient descent nào?\n",
      "Error encoding text 'Một thuật toán gradient descent lấy ra 32 dữ liệu điểm mỗi lần tính đạo hàm thì thuộc loại gradient descent nào?': Input Một thuật toán gradient descent lấy ra 32 dữ liệu điểm mỗi lần tính đạo hàm thì thuộc loại gradient descent nào? is too long for context length 77\n",
      "C\n",
      "Processing question 231: Input của bài toán object detection là?\n",
      "B\n",
      "Processing question 232: Vấn đề chính của R-CNN là?\n",
      "C\n",
      "Processing question 233: IoU phụ thuộc vào hai toán tử tập hợp nào và công thức là gì?\n",
      "A\n",
      "Processing question 234: Cốt lõi của các cách tiếp cận bài toán object detection là?\n",
      "B\n",
      "Processing question 235: ROI pooling với ảnh 10 x 10 và output 4 x 4 sẽ chia ảnh gốc thành mấy phân vùng\n",
      "C\n",
      "Processing question 236: Bộ dữ liệu được sử dụng có bao nhiêu ảnh?\n",
      "A\n",
      "Processing question 237: Mô hình được sử dụng để huấn luyện là?\n",
      "D\n",
      "Processing question 238: Có bao nhiêu phương pháp đã được dùng để tăng cường dữ liệu và gồm những thao tác nào?\n",
      "Error encoding text 'Có bao nhiêu phương pháp đã được dùng để tăng cường dữ liệu và gồm những thao tác nào?': Input Có bao nhiêu phương pháp đã được dùng để tăng cường dữ liệu và gồm những thao tác nào? is too long for context length 77\n",
      "D\n",
      "Processing question 239: Cách tiếp cận đã nêu trong bài có tiến hành đọc biển số hay không?\n",
      "A\n",
      "Processing question 240: Phân lớp của bài toán này là?\n",
      "A\n",
      "Processing question 241: Khái niệm được dùng để đại diện tập xác định của một biến là?\n",
      "A\n",
      "Processing question 242: Thành phần nào sau đây không thuộc phạm vi quản lý của biến?\n",
      "A,B,C\n",
      "Processing question 243: Tên kiểu dữ liệu của ký tự ASCII và ký tự Unicode lần lượt là?\n",
      "C\n",
      "Processing question 244: Đâu không phải khẳng định đúng về thuật toán?\n",
      "C\n",
      "Processing question 245: Phương trình toán học 3x + 4y + 5z = 6 có mấy biến?\n",
      "B\n",
      "Processing question 246: Điền vào chỗ trống: nếu hàm số f(x) bị ... bởi hằng số C nhân với g(x), ta nói f(x) có độ phức tạp O(g(x))\n",
      "Error encoding text 'Điền vào chỗ trống: nếu hàm số f(x) bị ... bởi hằng số C nhân với g(x), ta nói f(x) có độ phức tạp O(g(x))': Input Điền vào chỗ trống: nếu hàm số f(x) bị ... bởi hằng số C nhân với g(x), ta nói f(x) có độ phức tạp O(g(x)) is too long for context length 77\n",
      "B\n",
      "Processing question 247: Theo nguyên tắc tổng, f1(x) + f2(x) có độ phức tạp là?\n",
      "A\n",
      "Processing question 248: Độ phức tạp tuyến tính và giai thừa lần lượt có ký hiệu là?\n",
      "C\n",
      "Processing question 249: Bước đầu tiên của mỗi quá trình tiếp cận bài toán là?\n",
      "C\n",
      "Processing question 250: Hai thuật toán được tiến hành kế tiếp nhau lần lượt có độ phức tạp O(n) và O(n^2). Độ phức tạp của chương trình là?\n",
      "Error encoding text 'Hai thuật toán được tiến hành kế tiếp nhau lần lượt có độ phức tạp O(n) và O(n^2). Độ phức tạp của chương trình là?': Input Hai thuật toán được tiến hành kế tiếp nhau lần lượt có độ phức tạp O(n) và O(n^2). Độ phức tạp của chương trình là? is too long for context length 77\n",
      "B\n",
      "Processing question 251: Trong bốn khái niệm dưới, khái niệm nào không thuộc về thuật toán sinh?\n",
      "D\n",
      "Processing question 252: Nội dung của chương không bao gồm bài toán nào?\n",
      "D\n",
      "Processing question 253: Số hoán vị của một bộ độ dài N là bao nhiêu và giá trị tương ứng khi N = 3 là?\n",
      "A\n",
      "Processing question 254: Đâu là cốt lõi của thuật toán đệ quy?\n",
      "C\n",
      "Processing question 255: Bài toán liệt kê xâu nhị phân độ dài 6 phải trải qua bao nhiêu cấu hình, nếu biết số cấu hình cho độ dài n là 2^n?\n",
      "Error encoding text 'Bài toán liệt kê xâu nhị phân độ dài 6 phải trải qua bao nhiêu cấu hình, nếu biết số cấu hình cho độ dài n là 2^n?': Input Bài toán liệt kê xâu nhị phân độ dài 6 phải trải qua bao nhiêu cấu hình, nếu biết số cấu hình cho độ dài n là 2^n? is too long for context length 77\n",
      "D\n",
      "Processing question 256: Đâu không phải một ví dụ duyệt được thực hiện bởi quay lui?\n",
      "B,D\n",
      "Processing question 257: Trong bài toán N quân hậu, quân hậu ở hàng thứ i phải thỏa mãn điều gì?\n",
      "A\n",
      "Processing question 258: Thủ tục tiền xử lý và thủ tục chạy quay lui được gọi trong main() lần lượt là?\n",
      "D\n",
      "Processing question 259: Đâu không phải một bước trong quay lui?\n",
      "1. Duyệt một phần các khả năng của biến\n",
      "2. Đặt biến là một giá trị hợp lệ\n",
      "3. Di chuyển đến biến tiếp theo nếu còn\n",
      "Error encoding text 'Đâu không phải một bước trong quay lui?\n",
      "1. Duyệt một phần các khả năng của biến\n",
      "2. Đặt biến là một giá trị hợp lệ\n",
      "3. Di chuyển đến biến tiếp theo nếu còn': Input Đâu không phải một bước trong quay lui?\n",
      "1. Duyệt một phần các khả năng của biến\n",
      "2. Đặt biến là một giá trị hợp lệ\n",
      "3. Di chuyển đến biến tiếp theo nếu còn is too long for context length 77\n",
      "A,B,C,D\n",
      "Processing question 260: Nếu duyệt mọi tập con K phần tử có thể thực hiện bằng quay lui thì ta có thể dùng quay lui để duyệt một số tập con K phần tử hay không?\n",
      "Error encoding text 'Nếu duyệt mọi tập con K phần tử có thể thực hiện bằng quay lui thì ta có thể dùng quay lui để duyệt một số tập con K phần tử hay không?': Input Nếu duyệt mọi tập con K phần tử có thể thực hiện bằng quay lui thì ta có thể dùng quay lui để duyệt một số tập con K phần tử hay không? is too long for context length 77\n",
      "B\n",
      "Processing question 261: Điều kiện của \"sắp xếp\" là?\n",
      "A\n",
      "Processing question 262: Có thể nói, \"sắp xếp là sân sau của quá trình tìm kiếm\" hay không?\n",
      "B\n",
      "Processing question 263: Cho biết số lượng thuật toán sắp xếp đơn giản được trình bày và tên của chúng?\n",
      "C\n",
      "Processing question 264: Độ phức tạp nhỏ nhất của Insertion Sort là?\n",
      "A\n",
      "Processing question 265: Vì sao Selection Sort có độ phức tạp O(N^2)\n",
      "C\n",
      "Processing question 266: Hành động chính của Bubble Sort là?\n",
      "B\n",
      "Processing question 267: Đâu không phải một cách chọn khóa (pivot) điển hình trong Quick Sort\n",
      "B,C,D\n",
      "Processing question 268: Trong heap, chỉ số node con trái và phải của node x lần lượt là? (node gốc có chỉ số 0)\n",
      "A\n",
      "Processing question 269: Đâu là cấu trúc heap ta nên dùng nếu muốn sắp xếp mảng giảm dần?\n",
      "B\n",
      "Processing question 270: Đâu là điểm chung giữa Merge Sort và Quick Sort? Chọn một đáp án\n",
      "No match found\n",
      "Processing question 271: Đâu không phải thuật toán tìm kiếm được nêu trong tài liệu Public055?\n",
      "C\n",
      "Processing question 272: Thuật toán đơn giản nhất trong bốn thuật toán được nêu là?\n",
      "D\n",
      "Processing question 273: Kết quả trả về của tìm kiếm khi thấy và không thấy lần lượt là?\n",
      "C\n",
      "Processing question 274: Nhận định nào sau đây không đúng\n",
      "A\n",
      "Processing question 275: Biết tìm kiếm nhị phân luôn hoàn thành trong logN bước, cho biết mảng đã sắp xếp gồm 2^8 phần tử sẽ cần bao nhiêu bước?\n",
      "Error encoding text 'Biết tìm kiếm nhị phân luôn hoàn thành trong logN bước, cho biết mảng đã sắp xếp gồm 2^8 phần tử sẽ cần bao nhiêu bước?': Input Biết tìm kiếm nhị phân luôn hoàn thành trong logN bước, cho biết mảng đã sắp xếp gồm 2^8 phần tử sẽ cần bao nhiêu bước? is too long for context length 77\n",
      "B\n",
      "Processing question 276: Đâu không phải thao tác phổ biến trên linked list?\n",
      "C\n",
      "Processing question 277: Một node của linked list có mấy trường?\n",
      "B\n",
      "Processing question 278: Tên của thao tác cập nhật node và tìm node lần lượt là?\n",
      "D\n",
      "Processing question 279: Đâu không phải là đặc điểm của linked list?\n",
      "C\n",
      "Processing question 280: Muốn cập nhật trong linked list phần tử thứ 5 với giá trị 7, ta cần nhập vào khi gọi update() thứ tự giá trị nào cho pos và val?\n",
      "Error encoding text 'Muốn cập nhật trong linked list phần tử thứ 5 với giá trị 7, ta cần nhập vào khi gọi update() thứ tự giá trị nào cho pos và val?': Input Muốn cập nhật trong linked list phần tử thứ 5 với giá trị 7, ta cần nhập vào khi gọi update() thứ tự giá trị nào cho pos và val? is too long for context length 77\n",
      "B\n",
      "Processing question 281: Đâu không phải một loại đồ thị trong phân loại cấp dưới?\n",
      "C\n",
      "Processing question 282: Đồ thị được tạo thành bằng cách bổ sung một đỉnh nối với mọi đỉnh của đồ thị C_n được ký hiệu là?\n",
      "Error encoding text 'Đồ thị được tạo thành bằng cách bổ sung một đỉnh nối với mọi đỉnh của đồ thị C_n được ký hiệu là?': Input Đồ thị được tạo thành bằng cách bổ sung một đỉnh nối với mọi đỉnh của đồ thị C_n được ký hiệu là? is too long for context length 77\n",
      "A\n",
      "Processing question 283: Tên gọi riêng cho đỉnh bậc 0 và đỉnh bậc 1 trong đồ thị vô hướng là?\n",
      "B\n",
      "Processing question 284: Đâu không phải tên của một cách biểu diễn đồ thị?\n",
      "A\n",
      "Processing question 285: Đồ thị bánh xe là đồ thị tròn Cn được thêm vào n cạnh. Vậy số cạnh của đồ thị bánh xe là?\n",
      "Error encoding text 'Đồ thị bánh xe là đồ thị tròn Cn được thêm vào n cạnh. Vậy số cạnh của đồ thị bánh xe là?': Input Đồ thị bánh xe là đồ thị tròn Cn được thêm vào n cạnh. Vậy số cạnh của đồ thị bánh xe là? is too long for context length 77\n",
      "A\n",
      "Processing question 286: Đâu là một tên gọi khác của kiểm thử chức năng?\n",
      "B\n",
      "Processing question 287: Tập S biểu diễn hành vi như thế nào?\n",
      "A\n",
      "Processing question 288: Các hành vi \"được đặc tả\" và \"được kiểm thử\" được định nghĩa thuộc tập nào?\n",
      "Error encoding text 'Các hành vi \"được đặc tả\" và \"được kiểm thử\" được định nghĩa thuộc tập nào?': Input Các hành vi \"được đặc tả\" và \"được kiểm thử\" được định nghĩa thuộc tập nào? is too long for context length 77\n",
      "C\n",
      "Processing question 289: So sánh kiểm thử hộp trắng và kiểm thử hộp đen, phương pháp nào ưu việt hơn?\n",
      "C\n",
      "Processing question 290: Theo mô hình biểu đồ Venn, thiết kế kiểm chứng nên rơi vào miền nào nhiều nhất?\n",
      "D\n",
      "Processing question 291: Kiểm thử tích hợp tập trung vào vấn đề gì?\n",
      "B\n",
      "Processing question 292: Đâu không phải là một hình thức giao diện giữa nhiều module?\n",
      "B\n",
      "Processing question 293: Ngoài hai cách ghép module thông dụng là top down, bottom up thì còn mấy phương pháp và tên của chúng là?\n",
      "No match found\n",
      "Processing question 294: Nội dung nào không được đề cập?\n",
      "A,B,C,D\n",
      "Processing question 295: Đoạn code ngắn sau thể hiện loại giao diện nào?\n",
      "float pi() { return 3.14; } void main() { std::cout << pi(); }\n",
      "C\n",
      "Processing question 296: Toàn bộ chương sẽ đi qua bao nhiêu ví dụ?\n",
      "C\n",
      "Processing question 297: Có tất cả bao nhiêu cách để đi đến nút \"Not A Triangle\" trong bài toán Tam giác, theo tài liệu?\n",
      "No match found\n",
      "Processing question 298: Phân bố loại đối tượng nào là một vấn đề của bài toán Ngày kế tiếp; việc xác định đối tượng này có phụ thuộc vào đối tượng khác không?\n",
      "Error encoding text 'Phân bố loại đối tượng nào là một vấn đề của bài toán Ngày kế tiếp; việc xác định đối tượng này có phụ thuộc vào đối tượng khác không?': Input Phân bố loại đối tượng nào là một vấn đề của bài toán Ngày kế tiếp; việc xác định đối tượng này có phụ thuộc vào đối tượng khác không? is too long for context length 77\n",
      "C\n",
      "Processing question 299: Đâu không phải một yếu tố khiến bài toán Tam giác phổ biến?\n",
      "A\n",
      "Processing question 300: Output của bài toán tam giác với bộ ba số (3, 4, 5) là?\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# --- Input ---\n",
    "# Extract each row into a list of MCQInput objects\n",
    "mcq_list = []\n",
    "for _, row in df.iterrows():\n",
    "    mcq = MCQInput(\n",
    "        question=str(row['Question']) if pd.notna(row['Question']) else \"\",\n",
    "        option_a=str(row['A']) if pd.notna(row['A']) else \"\",\n",
    "        option_b=str(row['B']) if pd.notna(row['B']) else \"\",\n",
    "        option_c=str(row['C']) if pd.notna(row['C']) else \"\",\n",
    "        option_d=str(row['D']) if pd.notna(row['D']) else \"\"\n",
    "    )\n",
    "    mcq_list.append(mcq)\n",
    "\n",
    "# Now mcq_list contains all MCQInput objects\n",
    "print(f\"Total questions loaded: {len(mcq_list)}\")\n",
    "\n",
    "\n",
    "answers = []\n",
    "# Example: Process the first one (you can loop over all)\n",
    "for i, mcq in enumerate(mcq_list):  # Process first 5 for demo\n",
    "    print(f\"Processing question {i+1}: {mcq.question}\")\n",
    "    # Your existing code for retrieval and inference\n",
    "    retrieved_context = get_relevant_documents(mcq.question)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_context])\n",
    "    response = llm.invoke(prompt.format(context=context, **mcq.model_dump()))\n",
    "    # Extract answer using regex\n",
    "    pattern = r'\\{\"answer\":\\s*\"([A-D, ]+)\"\\}'\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "        print(f\"{answer}\")\n",
    "        answers.append(answer)\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "        answers.append('C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ee7aa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11520 - 11221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e90290d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'D',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A,B,C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B,C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'A',\n",
       " 'D',\n",
       " 'C',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A,B,C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'D',\n",
       " 'A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B,D',\n",
       " 'A',\n",
       " 'D',\n",
       " 'A,B,C,D',\n",
       " 'B',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " 'B',\n",
       " 'B,C,D',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'B',\n",
       " 'D',\n",
       " 'C',\n",
       " 'B',\n",
       " 'C',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'A',\n",
       " 'B',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " 'D',\n",
       " 'B',\n",
       " 'B',\n",
       " 'A,B,C,D',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f602f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (294) does not match length of index (300)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save answers to CSV file\u001b[39;00m\n\u001b[32m      2\u001b[39m output_df = df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43moutput_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAnswer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = answers\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m      6\u001b[39m output_path = \u001b[33m\"\u001b[39m\u001b[33manswers.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\APC\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\core\\frame.py:4316\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4313\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4315\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4316\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\APC\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\core\\frame.py:4529\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4520\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4521\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4522\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4527\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4529\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4532\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4533\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4534\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4535\u001b[39m     ):\n\u001b[32m   4536\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4537\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\APC\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\core\\frame.py:5273\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5273\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5274\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5276\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5277\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5280\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5281\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\APC\\miniconda3\\envs\\new\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (294) does not match length of index (300)"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_path = \"answers.csv\"\n",
    "output_df.to_csv(answers, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65eff68",
   "metadata": {},
   "source": [
    "## VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoModelForImageTextToText, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "# from transformers import AutoProcessor\n",
    "\n",
    "\n",
    "\n",
    "# def load_llm():\n",
    "#     # MODEL_PATH = \"Qwen/Qwen2.5-3B-Instruct\"  # Local model path\n",
    "#     MODEL_PATH = 'Qwen/Qwen2.5-VL-3B-Instruct'\n",
    "\n",
    "#     # ✅ Optimized 4-bit quantization config for Blackwell GPUs\n",
    "#     bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_use_double_quant=True,     # Nested quantization → less VRAM\n",
    "#         bnb_4bit_quant_type=\"nf4\",          # Best quantization format for LLMs\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16,  # BF16 is optimal on Blackwell\n",
    "#     )\n",
    "\n",
    "#     # ✅ Load tokenizer & model locally with full GPU optimization\n",
    "#     processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "#     model = AutoModelForImageTextToText.from_pretrained(\n",
    "#         MODEL_PATH,\n",
    "#         quantization_config=bnb_config,\n",
    "#         device_map=\"auto\",                  # Automatically spreads across GPUs if available\n",
    "#         torch_dtype=torch.bfloat16,         # Native dtype for new NVIDIA architectures\n",
    "#         trust_remote_code=True,\n",
    "#         local_files_only=True,\n",
    "#     )\n",
    "\n",
    "#     # model = AutoModelForCausalLM.from_pretrained(\n",
    "#     #     MODEL_PATH,\n",
    "#     #     quantization_config=bnb_config,\n",
    "#     #     device_map=\"auto\",                  # Automatically spreads across GPUs if available\n",
    "#     #     dtype=torch.bfloat16,         # Native dtype for new NVIDIA architectures\n",
    "#     #     local_files_only=True,\n",
    "#     # )\n",
    "\n",
    "#     # ✅ Enable better CUDA performance\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = True     # TensorFloat-32 acceleration\n",
    "#     torch.backends.cudnn.benchmark = True            # Optimize kernel selection\n",
    "#     torch.set_float32_matmul_precision(\"high\")       # Prefer high precision kernels\n",
    "\n",
    "#     # ✅ Create high-throughput inference pipeline\n",
    "#     generation_pipeline = pipeline(\n",
    "#         \"image-text-to-text\",\n",
    "#         model=model,\n",
    "#         tokenizer=processor.tokenizer,\n",
    "#         max_new_tokens=256,\n",
    "#         # temperature=0.7,\n",
    "#         # top_p=0.9,\n",
    "#         # repetition_penalty=1.1,\n",
    "#     )\n",
    "\n",
    "#     return HuggingFacePipeline(pipeline=generation_pipeline)\n",
    "\n",
    "\n",
    "# llm = load_llm()\n",
    "# print(\"Model device:\", next(llm.pipeline.model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3580c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
